#! /bin/bash

# ##/*! \file qa-DKRZ
## \brief Start script for the QA

## This script starts a Quality Assurance (QA) session.\n
## The script is started on the command-line with optional parameters.\n
## Example: <tt> path/QA-DKRZ/scripts/qa-DKRZ -f file.conf [opts] </tt> \n
## The script keeps track of netCDF files scheduled for processing
## (and those which have been processed). A quality check is performed
## by an executable of the \a qA_main.cpp file within
## the script \a qaExecutable_FS which in turn was launched by
## \a qa-DKRZ asynchronously parallel in the back-ground.
## User provided parameters from a configuration and/or task
## file as well as from the command-line are parsed by the
## script \a qaConfiguration.\n
##*/

##//! Apply rules for SELECTing and LOCKing of paths and files.
#
##/*! Syntax Rules of SELECT / LOCK ( [] indicates optional):\n
## <tt>SELECT [path1[, path2, ...] = ] [var1[, var2, ...]]</tt>\n
## SELECT/LOCK has a special syntax (with [] indicating optional):\n
## Note: '=' has a special meaning; mulitple assignments just add.
## Same for LOCK.

## A path is a sub-path appended to the tree given by PROJECT_DATA.
## Several SELECT and LOCK statements, respectively, are cumulative.
# ## There must be no assignment character '=' following key-words
## or SELECT or LOCK.
## Each variable specification is applied to all paths.\n
## Assignments may contain (and usually do) regular expressions.
## The rules of the RegExp must be those of the 'expr' command explained
## in 'man  grep'.
## This implies that each regExpr must begin from the first character
## with the caret ^ omitted. E.g. SELECT .* /historical /.* /Amon =
## Omitting path and variable defaults to all, respectively, i.e. '.*'\n
## Important: selecting one or more paths requires a '=' character behind
## the last path. Otherwise, it is taken as selection for variables.
## SELECT := starts a multiple line selection (same rules as for multiple
## line assignment).\n
## Same for LOCK. Multiple lines SELECTions may be mixed
## with such given by a single line.\n
## Note: SELECT in a config-file and via command-line option '-S arg'
## are combined; arg (without key-word SELECT) is as a single-line.\n
## Examples: \n
## SELECT path=var # specifies a single path where to look for a single ## variable \n
## SELECT p1,p2=var  #  two paths to look for a variable \n
## SELECT p1,p2=  #  two paths with every variable, equivalent to #p1,p2=.*  \n
## SELECT p1=v1,v2  #   one path with two variables \n
## SELECT var[,v2,v3]  #   looks for variables in the entire DRS tree \n
## SELECT p1=,p2=v1...  --> error,  SELECT  p1,p2=v1...  --> ok. \n
##*/

annot_summary_detectType()
{
  local qa_res=$1
  local logFName=${2%.log}

  if ! ls ${qa_res}/Annotations/* &> /dev/null ; then
    return 0
  elif ls ${qa_res}/Annotations/*.json &> /dev/null ; then
    return 0
  fi

  return 1
}

annot_summary()
{
  test ${NO_SUMMARY:-f} = t && return

  local i j
  for(( i=0 ; i < ${#LOG_FNAMES[*]} ; ++i )) ; do
    if [ -d ${LOG_FNAMES[i]} ] ; then
       # is a directory and the contained log-files are appended
       local log_fns
       declare -a log_fns
       log_fns=( $(ls ${LOG_FNAMES[i]}/*.log 2>/dev/null) )

       for(( j=0 ; j < ${#log_fns[*]} ; ++j )) ; do
          if [ $j -eq 0 ] ; then
             # overwrite item with the directory path
             LOG_FNAMES[i]=${log_fns[j]}
          else
             # append
             LOG_FNAMES[${#LOG_FNAMES[*]}]=${log_fns[j]}
          fi
       done
    fi

    if [ ${LOG_FNAMES[i]} != ${LOG_FNAMES[i]%.log} ] ; then
      LOG_FNAMES[${i}]=${LOG_FNAMES[i]%.log}
    fi

  done

  # look for e.g.: f0,path/f1,f2,... . apply first path to all relative files
  local lfn lfn_path exp_ix

  if [ ${ONLY_SUMMARY:-f} != f -a ${ONLY_SUMMARY:-f} != all ] ; then
    for(( exp_ix=0 ; exp_ix < ${#LOG_FNAMES[*]} ; ++exp_ix )) ; do
      if [ "${LOG_FNAMES[exp_ix]}" != "${LOG_FNAMES[exp_ix]#*/}" ] ; then
         lnf_path=${LOG_FNAMES[exp_ix]%/*}/
         break
      fi
    done

    for(( exp_ix=0 ; exp_ix < ${#LOG_FNAMES[*]} ; ++exp_ix )) ; do
      if [ "${LOG_FNAMES[exp_ix]}" = "${LOG_FNAMES[exp_ix]#*/}" ] ; then
         LOG_FNAMES[exp_ix]=${lnf_path}${LOG_FNAMES[exp_ix]}
         break
      fi
    done
  fi

  local cvr prj qrs tcl ers
  test ${PROJECT}    && prj="-P ${PROJECT}"
  test ${QA_RESULTS} && qrs="-r ${QA_RESULTS}"

  if [ ${TABLE_PATH} ] ; then
    tcl="-t ${TABLE_PATH}/${QA_CHECK_LIST}"
    tcfcl="-c ${TABLE_PATH}/${QA_CHECK_LIST}"
    test ${FIND_NOT_DELIVERED:-t} = t &&
      cvr="-s ${TABLE_PATH}/${TABLE_VAR_REQ}"
  fi

  if [ ${EMAIL_SUMMARY} ] ; then
    ers="${EMAIL_SUMMARY[*]}"
    ers=" -e ${ers// /,}"
  fi


  # multiple threads, but a maximum of 2
  exp_ix=0
  local pidBufMax=2
  local pidBuf
  local isStart=f
  local buf_ix=0
  local i

  for(( i=0 ; i < pidBufMax ; ++i )) ; do
    pidBuf[i]=''
  done

  local qa_res

  while [ ${exp_ix} -lt ${#LOG_FNAMES[*]} ] ; do
    for(( i=0 ; i < pidBufMax ; ++i )) ; do
      if [ "${pidBuf[i]}" ] ; then
        if ! ps -p ${pidBuf[i]} -o pid= &> /dev/null  ; then
          # there is still an active job for this fBase
          isStart=t
          break
        fi
      else
        isStart=t
        break
      fi
    done

    if [ ${isStart} = t ] ; then
      if [ "${LOG_FNAMES[exp_ix]}" != "${LOG_FNAMES[exp_ix]#*/}" ] ; then
         qa_res=${LOG_FNAMES[exp_ix]%/*}
         LOG_FNAMES[exp_ix]=${LOG_FNAMES[exp_ix]##*/}

         if [ ! -r $qa_res/${LOG_FNAMES[exp_ix]}.log ] ; then
           echo "$qa_res/${LOG_FNAMES[exp_ix]}: no such file or directory"
           continue
         fi
      else
         qa_res=${QA_RESULTS}/check_logs
      fi

      # detect the kind of summary structure (traditionally or new)
      if [ ${PY_SUMMARY:-f} = f -a ${TRADITIONAL_SUMMARY:-f} = f ] ; then
        if annot_summary_detectType ${qa_res} ${LOG_FNAMES[exp_ix]} ; then
           PY_SUMMARY=t
        else
           PY_SUMMARY=f
        fi
      fi

      if [ ${PY_SUMMARY:-f} = t ] ; then
         python ${QA_SRC}/python/qa-dkrz/qa_summary.py \
              ${qa_res}/${LOG_FNAMES[exp_ix]}

         # annot_summary_send ${qa_res}/Annotations/${LOG_FNAMES[exp_ix]}.json
      else
         /bin/bash ${QA_SRC}/scripts/taskSummary ${DEBUG_X} \
           -p ${qa_res} --src=$QA_SRC \
           ${cvr} ${ers} ${prj} ${qrs} ${tcl} ${LOG_FNAMES[exp_ix]}
      fi

      pidBuf[i]=$!
      isStart=f
      exp_ix=$((exp_ix+1))
    else
      sleep 1
    fi
  done

  wait
  return
}

annot_summary_send()
{
  # $1: path/filename of annotation summary

  test ! ${EMAIL_SUMMARY} && return
  test ! -f $1 && return

  local exp=${1##*/}
  exp=${exp%.json}
  local caption="QA-DKRZ: ${exp}"

  if which mutt &> /dev/null ; then
    mutt -s "${caption}" -a ${1} -- ${EMAIL_SUMMARY[*]}

  elif which mailx &> /dev/null ; then

    mailx -s "${caption}" ${EMAIL_SUMMARY[*]// /,} << EOF
$( cat ${1} )
EOF

  fi

  return
}

applyRules()
{
   # return 0 :: true

   local retVal
   retVal=1  # go for a file
   local f

   # Is there a race condition? Yes? Then wait.
   if [ ${PROC_POOL} ] ; then
     for f in $(ls ${PROC_POOL}/experiments/* 2> /dev/null) ; do
       if expr match "$f" ".*:${1}" &> /dev/null; then
         # the filename root matched. But, is it also the right path?
         # a race condition can also happen here in the pipe-line
         local tp
         tp="$( cat $f 2> /dev/null | head -n 3 | tail -n 1)"
         if [ ${tp} ] ; then
           tp=${tp#SUB_PATH=}
           test "$tp" != "${subPath}" && break  # is different
         fi

         return 0
       fi
     done
   fi

   if applySelectionRules $1 ; then
     return 0  # not selected
   fi

   if applyLockRules $1 ; then
     retVal=0  # not selected
   fi

   return $retVal
}

applyLockRules()
{
  # return 0, if locked
  # return 1, if not

  local refName pl sP
  refName=$1

  sP=${subPath}
  test ! ${sP} && sP='/.'

  test ${#LOCK_PATH_LIST[*]} -eq 0 -a ${#LOCK_VAR_LIST[*]} -eq 0  && return 1

  # any path selected?
  for(( pl=0 ;  $pl < ${#LOCK_PATH_LIST[*]} ; ++pl )) ; do
    if expr match ${sP} "${LOCK_PATH_LIST[pl]}" &> /dev/null ; then
      if expr match ${refName} "${LOCK_VAR_LIST[pl]}" &> /dev/null ; then
        return 0
      fi
    fi
  done

  return 1  # no locks found
}

applySelectionRules()
{
  # return 1, if selected
  # return 0, if not

  local refName pl sP
  refName=$1

  sP=${subPath}
  test ! ${sP} && sP='.'

  test ${#SELECT_PATH_LIST[*]} -eq 0 -a ${#SELECT_VAR_LIST[*]} -eq 0 && return 1

  # any path selected?
  for(( pl=0 ;  $pl < ${#SELECT_PATH_LIST[*]} ; ++pl )) ; do
    if expr match ${sP} "${SELECT_PATH_LIST[pl]}" &> /dev/null ; then
      # special: only the path is to be tested
      test "$1" = PATH && return 1

      # if no variable was selected, then all variables match
      if expr match ${refName} "${SELECT_VAR_LIST[pl]}" &> /dev/null ; then
        return 1
      fi
    fi
  done

  return 0  # no selection for the current sub-path
}

bind_checksum()
{
  local fs
  declare -a fs
  fs=( ${*##*/} ) # just the filename

  local type

  # extension corresponding to the checksum method
  cs_ext=md5

  if [ "${CHECKSUM}" = t ] ; then
    type='--type=md5'
  else
    cs_ext=${CHECKSUM%sum}
    cs_ext=${cs_ext##*/}
    type="--type=${CHECKSUM}"
  fi

  if [ ${CS_DIR} ] ; then
    if [ ${CS_DIR:0:1} = '/' ] ; then
      CS_TABLE="${CS_DIR}"
    else
      CS_TABLE="${QA_RESULTS}/${CS_DIR}"
    fi
  else
    test ${CS_STAND_ALONE:-f} = f && CS_TABLE="${QA_RESULTS}/cs_table"
  fi

  if [ ${CS_STAND_ALONE:-f} = t ] ; then
    if [ ! ${CS_TABLE} ] ; then
      CS_TABLE=${QA_RESULTS}/data/${subPath}
    fi
  fi

  local email
  if [ ${EMAIL_TO[0]} ] ; then
     email="${EMAIL_TO[*]}"
     email="-m ${email// /,}"
  fi

  if [ ${#LOG_PATH_INDEX[*]} -gt 0 ] ; then
    if ! getExperimentName P ${subPath} ; then
      getExperimentName F ${fs[0]}
    fi
  else
    getExperimentName F ${fs[0]}
  fi

  # calculate the checksum(s)
  ${QA_SRC}/scripts/checkSum -b ${QA_BIN#*:} $type \
      -q ${QA_RESULTS} ${YAML:+--yaml} ${CS_NO_HISTORY:+--no_history} \
      ${CS_STAND_ALONE:+-w}  $email ${CS_TABLE:+-t} ${CS_TABLE} \
      ${CURR_LOG_FNAME:+-x} ${CURR_LOG_FNAME} \
      -P ${PROJECT_DATA} -S ${subPath} ${fs[*]}

  return $?
}

callPing()
{
  # no ping necessary
  test "$1" == "$HOSTNAME" && return 0

  if [ ${PING_ENABLED:-f} = t ] ; then
    if $myPing -c 1 $1 &> /dev/null ; then
      return 0
    fi
  fi

  return 1
}

##//! User provided configuration setting from file and command-line.

##/*!
## Detailed comments on configuration parameters are given in files
## \a path/QA-DKRZ/tables/projects/*_qa.conf
##*/

callQaConfig()
{
# setting defaults, parsing of the configuration file and command-line  is left to the
# qaConfiguration, which returns key-word assignments and lists.
# NOTE: arrays of experiments and parameters are provided by the file
# LOGIDR/cache_request.txt.

  local items i key
  declare -a items

# necessary for returning embedded arrays from qaConfiguration
  OLD_IFS="$IFS"
  IFS="%"

#  set -f

# calling the configuration script
  if ! items=( $( ${QA_SRC}/scripts/$QA_CONFIG $* ) ) ; then
    # not necessarily an error; also SHOW_CONF, CHECK_TOOLS and
    # no argument for displaying help will return exit 1
    exit
  fi

  IFS="$OLD_IFS"

  if [ ! ${items[0]} ] ; then
    std_out flush "nothing configured, nothing to do.\nabnormal termination."
    lastStatus=1  # exit status of this script
    exit
  fi

  #enable settings for the qa
  set -f
  for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
    key="${items[i]%%=*}"

    # very specific: map PROJECT_DATA --> PROJECT_DATAV
    test ${key} = PROJECT_DATA && key=${key}V

    # any SHOW_... directive?
    test ${key:0:4} = SHOW && isShow=t

    if [ "${items[i]}" = "${items[i]// /}" ] ; then
      eval ${key}="${items[i]#*=}"
    else
      eval ${key}=\("${items[i]#*=}"\)
    fi

    # collection of variable names for tables (doesn't matter if
    # non-files are among them)
    if [ ${key%%_*} = TABLE ] ; then
      tableCandidates[${#tableCandidates[*]}]=${key%=*}
    elif [ ${key%%_*} = CF ] ; then
      tableCandidates[${#tableCandidates[*]}]=${key%=*}
    elif [ "${key/CHECK_LIST/}" != "${key}" ] ; then
      tableCandidates[${#tableCandidates[*]}]=${key%=*}
    fi

    setKWL ${key}
  done
  set +f

  # invoked by option -E_DEBUG_MANAGER
  if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
    exec 7<&2
    dbgCycle=0
    exec 2>${DEBUG_MANAGER}.$dbgCycle
    set -x
  elif [ ${DEBUG_MANAGER:-f} = t ] ; then
    set -x
  fi

  if [ ${DEBUG_X} ] ; then
    # debug-mode for external scripts
    if [ ${DEBUG_X} = t ] ; then
      DEBUG_X=--debug
    else
      DEBUG_X="--debug=${DEBUG_X}"
    fi
  fi

  if [ ${DISPLAY_VERSION} ] ; then
    ${QA_SRC}/scripts/getVersion --verbose \
        --config-file=${CONFIG_FILE} ${PROJECT} ${DEBUG_MANAGER:+--debug}
    exit 0
  fi

  test ${RESUME_SESSION:-f} = t && log_sessMessage "session resumed."

  test ${LOG_PATH_INDEX:-f} = f && DISABLE_CONSISTENCY_CHECK=t

  # always set
  PATH=${QA_BIN#*:}:$PATH

  #save for NIGHT_SHIFT operation
  save_QA_EXEC_HOSTS=( ${QA_EXEC_HOSTS[*]} )
  save_NUM_EXEC_THREADS=( ${NUM_EXEC_THREADS[*]} )

  QA_DATADIR=${QA_RESULTS}/data

#  set +f

  if [ "${SHOW_CLEAR}" ] ; then
    # SHOW_CLEAR may contain the same assignment as CLEAR itself
    test ! ${CLEAR} && CLEAR="${SHOW_CLEAR}"
    SHOW_CLEAR=t
  fi

  if [ ! ${CONDA_QA_PATH} ] ; then
    local lib
    lib=$( grep '^[[:space:]]*LIB=' ${QA_SRC}/install_configure )
    export LD_LIBRARY_PATH=$(eval echo "${lib#*=}")
  fi

  return
}

##//! Launcher of the executable of QA main-program qA_main.cpp

##/*!
## The script runs in the back-round. Hence, multiple instances may
## be proccessed in parallel. The script processes also annotations.
##*/

callQaExecutor()
{
  local nextFile
  local nextPeriod

  local i args item keyW w

  # this is the ultimative test (and unnecessary)
  test $# -eq 0 && return

  local LOG_FNAME=$CURR_LOG_FNAME

  nextFile=$1
  nextPeriod=$( getDateRange $nextFile )

  # Create semaphore file.
  local str
  str=${nextFile%.nc}

  local DT
  DT=$( date +'%F_%T' )

  # with next identification number
  procFile=$PROC_POOL/"${nextHost%%.*}:${str}_$((++EX_ID)).txt"

  local text
  text="NEXT_FILE=${nextFile}"

  test ${nextPeriod} \
      && text="${text}\nNEXT_PERIOD=${nextPeriod}"
  test ${subPath} \
      && text="${text}\nSUB_PATH=${subPath}"

  # 'export' the terminal device
  test -c "$TTY" && text="${text}\nTTY=${TTY}"

#  log_sessMessage \
#    "${nextHost%%.*}: ${subPath}/${nextFile}: start"

  local k
  k=0 # index for optional keyW items

  # key-words with assignment for the executor
  keyW=( ${keyW[*]} \
          APPLY_MAXIMUM_DATE_RANGE \
          ARITHMETIC_MEAN \
          CF \
          CF_FOLLOW_RECOMMENDATIONS \
          CF_NOTE \
          CF_NOTE_ALWAYS \
          CF_NOTE_LEVEL_LIMIT \
          CHECK_MODE \
          CHECKSUM \
          CONFIG_FILE \
          CS_STAND_ALONE \
          CS_TABLE \
          DATA_IN_PRODUCTION \
          DEFAULT_VALID_MAX \
          DEFAULT_VALID_MIN \
          DISABLE_INF_NAN \
          DISABLE_TIME_BOUNDS_CHECK \
          EMAIL_TO \
          EXCLUDE_ATTRIBUTE \
          EXCLUDE_VARIABLE \
          FILE_NAME_MIP_INDEX \
          FILE_NAME_VAR_INDEX \
          FD_BARS \
          FD_EXPLICIT_PROPS \
          FD_PLAIN \
          FD_PROPERTY_PATH \
          FD_TIME_PART \
          FILE_SEQUENCE \
          FREQ_DIST \
          FREQUENCY \
          IMPORTED_PATH \
          IGNORE_REFERENCE_DATE \
          IGNORE_REF_DATE_ACROSS_EXP \
          LOG_CPU_TIME \
          LOG_FNAME \
          LOG_FNAME_DIR \
          MAIL \
          MIP_FNAME_TIME_SZ \
          MIP_TABLE_NAME \
          NEVER_BREAK_SESSION \
          NEXT_RECORDS \
          NICE \
          NIGHT_SHIFT \
          NON_REGULAR_TIME_STEP \
          NOTE \
          NOTE_ALWAYS \
          NOTE_LEVEL_LIMIT \
          OUTLIER_TEST \
          PARENT_EXP_ID \
          PARENT_EXP_RIP \
          PING_ENABLED \
          POST_PROC \
          PRINT_GREP_MARK \
          PROC_POOL \
          PROJECT \
          PROJECT_DATA \
          PROJECT_TABLE \
          QA \
          QA_HOST \
          QA_NCFILE_FLAGS \
          QA_RESULTS \
          QA_SRC \
          REATTEMPT_LIMIT \
          REPLICATED_RECORD \
          RUN_CMOR3_LLNL \
          SESSION \
          SESSION_LOGDIR \
          SHOW_CALL \
          SLEEP_TIME \
          TIME_LIMIT \
          TRACKING_ID_ONLY \
          UNLIMITED_DIM_NAME \
          USE_STRICT \
          WORK_AT_LOW_LOAD \
  )

  keyW=( ${keyW[*]} ${tableCandidates[*]} )
  i=0

  test ! ${DEBUG_MANAGER} && voidX

  #use keywords and corresponding values to construct file in pool

  for item in ${keyW[*]} ; do
     eval w="\${${item}[*]}"
     test -z "$w" && continue

     text="${text}\n${item}=${w}"
  done
  test ! ${DEBUG_MANAGER} && voidX

  # call qaExecutor with arg-list: format: name=value
  # Note: if execution takes place on a host different than
  # the one where qa-DKRZ runs, then all paths must be
  # accessible.

  local prevPID=$currPID
  local ca
  test ${FLOW_TRACE:-f} = t && ca="FLOW_TRACE=t "
  test ${DEBUG_EXECUTOR:-f} = t && ca="${ca} DEBUG_EXECUTOR=t "

  if [ "$nextHost" = "${HOSTNAME:0:${#nextHost}}" ] ; then
    # use the first item of the QA_BIN array

    text="${text}\nIMPORTED_PATH=${QA_BIN#*:}"
    echo -e "$text" > $procFile

    $QA_SRC/scripts/$QA_FILE_EXECUTER "${ca}QA_SRC=${QA_SRC} \
         PROC_POOL=$PROC_POOL PROC_FILE=${procFile##*/} PAR_PID=${rootPID}" &
  else
    local bin
    for bin in ${QA_BIN[*]} ; do
      if [ "${nextHost}" = ${bin%:*} ] ; then
        text="${text}\nIMPORTED_PATH=${bin#*:}"
        break
      fi
    done

    echo -e "$text" > $procFile

    if callPing ; then
      ssh $nextHost $QA_SRC/scripts/$QA_FILE_EXECUTER "PROC_POOL=$PROC_POOL PROC_FILE=${procFile##*/} PAR_PID=${rootPID} &" &> /dev/null
    fi
  fi

  currPID=$!

  return
}

##//! Process scheduler
##/*!
## A frame function with life-span over the entire session.
## Keeps track of paths, files and running processes.
##*/

check()
{
  # The sequence of sub-temporal files is stored in a stack, which
  # is processed on after another. This is different to the
  # horizontal approach, when, after having processed the next
  # sub-temp file  of a given variable, the next variable is touched,
  # also only for the very next sub-temporal file.
  # There are a number of stacks corresponding to the number of hosts and
  # threads prescribed in the configuration.
  nFcurr=0
  nFmax=0
  currPID=0
  waitCounter=0

  local line subPath
  declare -a line

#  set +f

  # save stdin
  exec 9<&0

  # connect file to input;
  # keep it open for reading while more paths may be appended.
  exec 0< ${pathListFile}

  while : ; do

    while : ; do
      # read next sub path from pathListFile, get all variables
      # contained within after having looked for locks.

#trace \
      getNextSubPath

      for(( ix=0 ; ix < ${#fBase[*]} ; ++ix )) ; do

        if \
#trace \
          operatePipes ${subPath} ; then break 3 ; fi

#trace \
        checkClosedMessages
      done
    done

  done

  # restore stdin and free #9
  exec 0<&9 9<&-

  # this is for a wipe out run
  test ${isCLEAR_ONLY:-f} = t && exit

  # don't remove everything done so far in the next looping
  test ${CLEAR} && unset CLEAR

  # Just wait, give the qaExecutor(s) a chance to finish.
  # This does not work for qaExecutor instances launched by ssh.
#trace \
  wait_fnct

  return
}

##//! Finialisation of annotations of each check.

##/*!
## Communication between \a qa-DKRZ and \ qaExecutor is done
## by temporary files. After closing an qaExecutor instance, this
## function finalises annotation processes.
##*/

checkClosedMessages()
{
  # qaExecutors have added locked or closed files for finished runs
  local expName f fs ffs ff g
  declare -a ffs

  fs=( $( ls $PROC_POOL/*.closed 2> /dev/null ) )

  for f in ${fs} ; do
    expName="$( grep LOG_FNAME= $f )"
    expName=${expName#LOG_FNAME=}

    # experiment log-file
    ffs=( $( ls $PROC_POOL/experiments/$expName.*.log 2> /dev/null ) )
    for ff in ${ffs[*]} ; do
      if \
         tryCom get_status \
         test -s $ff  ; then

         if [ ${STDOUT_RESULTS} ] ; then
            while read line ; do
                word=( ${line} )
                test ${word[0]} = 'file:'      && echo -e "\n${line}"
                test ${word[0]} = 'data_path:' && echo "${line}"
                test ${word[0]} = 'annotation:'   && echo "${line}"
            done < ${ff}
         fi

         tryCom \
         cat "$ff" >> $LOG_FNAME_DIR/${expName}.log

         tryCom \
         \rm -f "$ff"

#         isAnythingDone=t
      fi
    done

    # logs of qA.x execution time
    if [ ${LOG_CPU_TIME:-f} = t ] ; then
      ffs=( $( ls $PROC_POOL/experiments/$expName.*.time 2> /dev/null ) )
      local line items
      declare -a items
      for ff in ${ffs[*]} ; do
        if \
           tryCom get_status \
           test -s $ff
        then
           # remove obsolete entries, thus we have to read one by one
           while read line ; do
             items=( ${line} )
             if grep -q ${items[3]} $LOG_FNAME_DIR/${expName}.time &> /dev/null ] ; then
                sed -i "/${items[3]}/d" $LOG_FNAME_DIR/${expName}.time
             fi

             echo "$line" >> $LOG_FNAME_DIR/${expName}.time
           done < $ff
           \rm -f "$ff"
        fi
      done
    fi

    # session log-file
    ffs=( $( ls $PROC_POOL/session/$SESSION.*.log 2> /dev/null ) )
    for ff in ${ffs[*]} ; do
      if \
         tryCom get_status \
         test -s $ff  ; then
         cat $ff >> $SESSION_LOGDIR/session.log
         \rm -f "$ff"
      fi
    done

    \rm  $f
  done

  return
}

##//! Look for lock-files preventing processing of a file.

##/*!
## Certain level of annotation cause the creation of a lock-file,
## which inhibits further processing of a given variable.
##*/

checkLockFile()
{
   # return 0 :: true
   # $1        : nc-file if any

   local name=${1%.nc}
   name=${name##*/}

   # any variable locked?
   if ls ${QA_RESULTS}/data/${subPath}/*_lock_${name}.txt &> /dev/null ; then
     countLockedVars=$(( countLockedVars + 1 ))
     return 0
   elif [ ${LOCK_NOTES:-f} = t ] ; then
     if ls ${QA_RESULTS}/data/${subPath}/*_note_${1}.txt &> /dev/null ; then
        countLockedVars=$(( countLockedVars + 1 ))
        return 0
     fi
   fi

   return 1
}

checkCorruptedQA()
{
  # Probe corrupt file due to a crash.
  # Return 0, i.e. true, if there is no solution
  local fs p v

  p=$1 # path
  v=$2 # filename name

  tryCom \
  test -d $p

  fs=$( ls $p/z_qa_${v}.nc 2> /dev/null)

  # Any previous backup file available? Yes. Then a crash happened.
  # Restore backup.
  if [ ${fs} ] ; then
    mv $p/z_qa_${v}.nc $p/qa_${v}.nc

    if [ -d $p/Z_fd_${v} ] ; then
      \rm -f $p/fd_${v}*.build
      if ls $p/Z_fd_${v}/* &> /dev/null ; then
        cp $p/Z_fd_${v}/* $p &> /dev/null
      fi
      rmdir $p/Z_fd_${v}/* &> /dev/null
    fi

    return 1
  fi

  # A crash happened while the file was open the first time.
  # No backup is available.
  fs=$( ls $p/qa_${v}.nc 2> /dev/null)

  if [ ${fs} ] ; then
    return 1 # no previous check at all
  fi

  if ! testValidNC.x $fs ; then
    # clear a corrupt file
    \rm -f "$fs"
  fi

  return 1
}

##//! Clear lock-files

##/*!
## Lock-files from a previous session are removed.
##*/

clear()
{
  local f fs t tx ts
  declare -a fs ts

  local isFL=f
  local isResume=f
  local isMessage=f

  isClear=t  # global scope

  # arbitrary order of arguments
  for f in ${CLEAR//,/ } ; do
    test ${CLEAR} = t && break  # unconditional

    isClear=f

    if [ "$f" = follow_links ] ; then
       test ${DEREFERENCE_SYM_LINKS:-f} = f && isFL=t
       isClear=t
    elif [ "${f:0:3}" = res ] ; then
       isResume=t
       isClear=t
    elif [ "$f" = only ] ; then
       isCLEAR_ONLY=t
       isClear=t
    elif [ "${f:0:4}" = lock ] ; then
       # locked  files
       if ls ${QA_RESULTS}/data/${subPath}/qa_lock_${fBase[ix]}* &> /dev/null ; then
         isClear=t
       fi
    elif [ "${f:0:4}" = note ] ; then
       # if any note
       if ls ${QA_RESULTS}/data/${subPath}/qa_note*_${fBase[ix]}* &> /dev/null ; then
         isClear=t
       fi
    elif [ "${f:0:4}" = mark ] ; then
       # only pass those that are locked; redo erroneous cases
       if ls ${QA_RESULTS}/data/${subPath}/clear.mark &> /dev/null \
            && ls ${QA_RESULTS}/data/${subPath}/${fBase[ix]}.clear &> /dev/null ; then
         isClear=t
       fi
    elif [ ${f%=*} = level -o ${f%=*} = tag ] ; then
       if [ ${f%=*} = level ] ; then
         # clear specified level
         f="^${f#*=}-"
       else
         # e.g. L1-${tag}: where tag=CF_12 would match CF_12, CF_12x etc.
         f="^[[:alnum:]]*-*${f#*=}.*: "
       fi

       local fl
       for fl in \
         $(ls ${QA_RESULTS}/data/${subPath}/qa_note_${fBase[ix]}* 2> /dev/null) \
         $( ls ${QA_RESULTS}/data/${subPath}/qa_lock_${fBase[ix]}* 2> /dev/null)
       do
        if grep -q $f $fl &> /dev/null ; then
          isClear=t
          break
        fi
       done
    elif [ ${f} != ${f/=/} -a ${f%=*} = var ] ; then
       # CLEAR=var=name
       if expr match ${fBase[ix]} "${f}" &> /dev/null ; then
         if ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* &> /dev/null
         then
           isClear=t
         fi
       fi
    else
       # CLEAR=varName
       f=${f%_} # this would allow for a variable 't_', which can be confused
                # without '_' with 't' meaning enabled.

       if expr match ${fBase[ix]} "${f}" &> /dev/null ; then
         if ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* &> /dev/null
         then
           isClear=t
         fi
       fi
    fi

    test ${isClear} = t && break
  done

  if [ ${isClear} = t ] ; then
    if [ "${isFL}" = t ] ; then
      # follow links
      fs=( $( \
           tryCom \
           ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* 2> /dev/null ) )

      for f in ${fs[*]} ; do
        if [ -h $f ] ; then
           deref_link target ${f}
           target=${target%/*}

           ts=( $( \
                tryCom \
                ls ${target}/*_${fBase[ix]}* 2> /dev/null  ) )

           for t in ${ts[*]} ; do
             if [ $isResume = t ] ; then
                tx=${t##*/}
                test "${tx:0:7}" != 'qa_lock' && continue
             fi

             if [ "${SHOW_CLEAR}" ] ; then
               std_out ttyOnly "\nSUB-PATH=${subPath}"
               std_out ttyOnly "\n\t${t}\tLINK\n"
             else
               # note: '\rm -f any' returns always 'true'
               if \
                  tryCom get_status \
                  \rm $t  ; then
                  isMessage=t
               fi
             fi
           done

           break
        fi
      done

      if [ $isMessage = t ]  ; then
        if [ $isResume = t ] ; then
          # only write a log message if targets of sym links were removed
          headerText="File:\t\tqa_${fBase[ix]}\n\
QA result path: ${target}\nResume: removed qa-break file by following links."
        else
          headerText="File:\t\tqa_${fBase[ix]}\n\
QA result path: ${target}\nRemoved QA results by following links."
        fi

        log_sessMessage "$headerText"
        isMessage=f
      fi
    fi

    # clearing section for regular files
    local isRm=f

    fs=( $( \
            tryCom get_status \
            ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* 2> /dev/null ) )

    test -e ${QA_RESULTS}/data/${subPath}/core && fs[${#fs[*]}]=core

    for f in ${fs[*]} ; do
      if [ $isResume = t ] ; then
        tx=${f##*/}
        if [ "${tx:0:7}" = 'qa_lock' -o "${tx}" = 'core' ] ; then
          fs=($f)
          isRm=t
          break
        fi
      else
        # remove all

        isRm=t
        break
      fi
    done

    if [ ${isRm} = t ] ; then
       if [ "${SHOW_CLEAR}" ] ; then
         std_out ttyOnly "\nSUB-PATH=${subPath}"
         std_out ttyOnly "\n\t${fBase[ix]}\n"
         return 0
       else
         # remove selected
         tryCom \
         \rm -f "${fs[*]}"
         isMessage=t
       fi
    else
       test "${SHOW_CLEAR}" && return 0
    fi

    # also delete log-table entries
    rmBlock $LOG_FNAME_DIR/$CURR_LOG_FNAME.log ${fBase[ix]}

    # and also delete consistency table entries
#    rmConsistTableEntry $LOG_FNAME_DIR/$CURR_LOG_FNAME.log ${fBase[ix]}

    if [ "$isMessage" != f ] ; then
      local note
      if [ ${isResume} != f ] ; then
         note="Resume: removed only qa-lock file."
      elif [ ${target} ] ; then
         note="Removed symbolic links."
      else
         note="Cleared QA results."
      fi

      # only write a log message if anything was removed
      headerText="File:\t\tqa_${fBase[ix]}\nPath: \t\t$PROJECT_DATA\n\
QA result path: $QA_RESULTS/data\nDRS tree:\t${subPath}\n${note}"

      log_sessMessage "$headerText"
    fi

    return 0
  fi

  return 1
}

copyPreamble()
{
  test ${isShow:-f} = t && return

  if [ -f ${SESSION_LOGDIR}/session.prmbl ] ; then
    cp ${SESSION_LOGDIR}/session.prmbl $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log
  fi

  return
}

cpTables()
{
   local key=$1
   local fTable=$2  # src table name
   local pTable=$3  # dest table name for project
   local prj_from=$4
   local prj_to=$5

   if [ ${#pDir[*]} = 0 ] ; then
      if [ ${prj_from} = ${prj_to} ] ; then
         # regular precedence of paths, i.e. highest first
         if [ -f $fTable ] ; then
            if [ ${fTable/\//} != ${fTable} ] ; then
               # local file
               pDir[${#pDir[*]}]=''
            else
               # with path
               pDir[${#pDir[*]}]=$fTable
            fi
         fi

         if [ ${USE_STRICT:-f} = f -a ${prj_from} = ${prj_to} ] ; then
            # USE_STRICT: only the project\'s default directory
            pDir[${#pDir[*]}]=${QA_TABLES}/tables/${prj_from}
         fi

         pDir[${#pDir[*]}]=${QA_TABLES}/tables/projects/${prj_from}
      else
         # the only possible place
         pDir[${#pDir[*]}]=$QA_TABLES/tables/$prj_from
      fi
   fi

   if [ ${prj_from} = ${prj_to} ] ; then
      if [ ${prj_from} != CF ] ; then
         test ${fTable:0:3} = 'CF_' -o  ${fTable:0:3} = 'cf-' && \
            pDir[${#pDir[*]}]=$QA_TABLES/tables/projects/CF
      fi
   fi

   local dest src
   if [ ${key/CHECK_LIST/} != ${key} ] ; then
      # Concatenate (may-be just a copy of a single file) existing check-lists.
      # Is any of the files newer than the destination?
      local pD
      for pD in ${pDir[*]} ; do
         src=$pD/$fTable

         if [ -f ${src}  ] ; then
            if [ ${prj_from} = ${prj_to} ] ; then
               dest=$TABLE_PATH/$pTable
            else
               dest=$TABLE_PATH/$fTable
               mv $TABLE_PATH/$pTable $dest

               # exchange properties of corresponding project file
               setKWL ${key}=${fTable}
            fi

            cat $src $dest > $dest.$$
            mv $dest.$$ $dest
            break
         fi
      done
   else
      # just copy the file with highest precedence; there should only
      # be a single one for each kind of table
      local pD
      for pD in ${pDir[*]} ; do
         src=$pD/$fTable

         if [ -f ${src} ] ; then
            if [ ${prj_from} = ${prj_to} ] ; then
               dest=$TABLE_PATH/$pTable
            else
               dest=$TABLE_PATH/$fTable
               rm -f  $TABLE_PATH/$pTable

               # exchange properties of corresponding project file
               setKWL ${key}=${fTable}
            fi

            local dest_modTime=$($QA_SRC/bin/fModTime.x ${dest} 2> /dev/null )
            local src_modTime=$($QA_SRC/bin/fModTime.x ${src} )

            test ${src_modTime} -gt ${dest_modTime} 2> /dev/null && cp $src $dest
         fi
      done
   fi

   return
}

disableStatusLine()
{
  # no status line for SHOW_CALL
  if [ ${SHOW_CALL:-f} = t -o ${SHOW_CLEAR:-f} = t ] ; then
    NO_STATUS=t
    SIMPLE_STATUS_LINE=f
    NO_STATUS=f
    return 0
  fi

  # no status line at all
  if [ ${SIMPLE_STATUS_LINE:-f} = f ] ; then
    NO_STATUS=t
    return 0
  fi

  return 1
}

displayStatusLine()
{
  local pbForStatus

  if [ "${progressAtomicNum}" -a ${progressTotalAtomicNum:-0} -gt 0  ] ; then
    pbForStatus=" (${progressAtomicNum}/${progressTotalAtomicNum})"

    local perc=$( echo "${progressAtomicNum} / ${progressTotalAtomicNum} * 100" | bc -l)
    # use if-construct, because this only works on AIX
    local is=$( echo "if ( ${perc} >= ${progressNext} ) 1" | bc -l )
    if [ ${is:-0} -eq 1 ] ; then
      # get next step
      is=$( echo "$perc / $progressStep" | bc -l )
      #discard decimal
      local i
      for(( i=0 ; i < ${#is} ; ++i )) ; do
         test ${is:i:1} = '.' && break
      done
      progressNext=$( echo "${is:0:i} * $progressStep +$progressStep" | bc -l)

      if [ ${PROGRESS_BAR} ] ; then
        eval echo "${progressAtomicNum} ${progressTotalAtomicNum}" ${progressFile}
      fi
    fi
  fi

  # no status line
  test ${SIMPLE_STATUS_LINE:-f} = f && return

  local num=$1
  shift
  local line="$*"

  local blank='          '
  local rpts=$(( repeats + 1 ))
  for(( l=0 ; l < rpts ; ++l )) ; do
    blank=${blank}'          '
  done
  std_out ttyOnly "\r${blank}\r"

  test ${num} -eq 0 && return

  std_out ttyOnly "${line} $pbForStatus"
  rp_num=$(( ${num} +15 ))
  repeats=$(( rp_num / 10 ))

  return
}

deref_link()
{
  # this is a robust version to dereference links, indepent on
  # the number of items given as output by 'ls -l'

  # $1: variable name to store the dereferenced file name
  # $2: the link

  local arr ipos
  declare -a arr

  arr=( $( \
           tryCom \
           ls -l $2 ) )

  for(( ipos=${#arr[*]}-1 ;ipos > -1 ; --ipos )) ; do
     test "${arr[ipos]}" = '->' && break
  done

  eval ${1}=${arr[$((ipos+1))]}

  return
}

executorRequestedExit()
{
  std_out flush "An executor instance requested EMERGENCY_STOP\nPlease, look for the reason in the session log-file."

  finally
  return
}

##//! Terminate current session

finally()
{
  test ${ONLY_SUMMARY:-f} = f && displayStatusLine 0

  wait_fnct  # give background processes a chance to finish;
             # locked processes are killed after a longer while

  if [ ${isTERM:-f} = t ] ; then
     # clear current results
     \rm -rf $PROC_POOL/*
  fi

  # release file with pid, if the session finished
  # rm filename with appended pid
  tryCom \
  \rm -f $QA_RESULTS/session_logs/PID/pid.$rootPID

  # directory containing files with PIDs of current qa-DKRZ runs.
  rmdir $QA_RESULTS/session_logs/PID &> /dev/null # only if empty

  test ${FLOW_TRACE:-f} = t && tracePrint

  # Note: there could be 2 sub-dirs and files in PROC_POOL during operation
  local f fs
  declare -a fs
  fs=( $( ls -d $PROC_POOL/* 2> /dev/null) )

  local count=0
  while [ ${#fs[*]} -gt 2 ] || ls -d $PROC_POOL/*/* 2> /dev/null ; do

    # the OS may have slow FS operations
    if [ $((count++)) -lt 5 ] ; then
      # final update of log-files
      checkClosedMessages

      sleep 0.1
      fs=( $( ls -d $PROC_POOL/* 2> /dev/null) )
      continue
    fi

    sendSubject=" PROC_POOL not cleared"
    sendText="qa-DKRZ.finally: ${PROC_POOL} was not cleared."

    log_sessMessage "$sendText"
    sendEMail
    break
  done

  std_out flush

  # rm PROC_POOL
  \rmdir ${PROC_POOL}/* 2> /dev/null
  \rmdir ${PROC_POOL}   2> /dev/null

  if [ ${IS_SINGLE_FILE_MODE} ] ; then
     if [ -f $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log ] ; then
        cat $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log

        \rm -r ${QA_RESULTS}
        exit 0
     fi
  fi

  # rm pid-saving file
  \rm -f ${SESSION_LOGDIR}/pid.$rootPID

  if [ ${isShow:-f} = f -a ${isTERM:-f} = f ] ; then
#    if [ ${isAnythingDone:-f} = t -a ${NO_SUMMARY:-f} = f ] ; then
    if [ ${NO_SUMMARY:-f} = f ] ; then
      annot_summary
    fi
  fi

  if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
    set +x
    exec 2<&7 7<&-
    test ${dbgCycle} -eq 0 && \
      tryCom \
      mv ${DEBUG_MANAGER}.${dbgCycle} ${DEBUG_MANAGER}
  fi

  # remove empty paths from the results
  rmEmptyPaths

  echo "number of processed files: ${countProcessedFiles}"

  countSelectedVars=$((countSelectedVars - countLockedVars ))
  countSelectedVars=$((countSelectedVars - countProcessedFiles ))

  if [ ${countSelectedVars} -gt 0 ] ; then
    echo "number of un-processed variables: ${countSelectedVars}"
  fi
  if [ ${countLockedVars} -gt 0 ] ; then
    echo "number of locked variables: ${countLockedVars}"
  fi

  if [ ${isTERM:-f} = t ] ; then
    kill -INT $$ 2&> /dev/null
  else
    exit ${lastStatus:-0}
  fi
}

##//! Show selected experiment names and exit.
getAllExps()
{
  local countLines
  local line
  local supPath
  local timeCounter=0

  declare -a line

  # save stdin
  exec 9<&0

  # connect file to input;
  # keep it open for reading while more paths may be appended.
  exec 0< $pathListFile

  while : ; do  # this loop resets when a race was lost

    while read -a line ; do
      test ${line[0]} = '---EOF---' && break 2

      subPath=${line[1]}
      PROJECT_DATA=${PROJECT_DATAV[${line[0]}]}

      # generate an experiment name; CURR_LOG_FNAME gets a 'return value'
      if [ ${#LOG_PATH_INDEX[*]} -gt 0 ] ; then
        if ! getExperimentName P ${subPath} ; then
          local fs=( $( ls ${PROJECT_DATA}/${subPath}/*.nc 2> /dev/null) )
          getExperimentName F ${fs[0]##*/}
        fi
      else
        local fs
        declare -a fs
        fs=( $( ls ${PROJECT_DATA}/${subPath}/*.nc 2> /dev/null) )
        getExperimentName F ${fs[0]##*/}
      fi

      if [ ${SHOW_LOG_FNAME:-f} = t ] ; then
        for(( i=0 ; i < ${#SLF[*]} ; ++i )) ; do
           test ${SLF[i]} = ${CURR_LOG_FNAME} && continue 2
        done
        SLF[i]=${CURR_LOG_FNAME}

        std_out ttyOnly "LOG_FNAME=${CURR_LOG_FNAME}\n"
      elif [ ${SHOW_EXP:-f} = t ] ; then
        std_out ttyOnly "\r${blank}\r"
        std_out ttyOnly "LOG_FNAME=${CURR_LOG_FNAME}\n"
        std_out ttyOnly "PATH=${PROJECT_DATA}/${subPath}\n\n"
      fi
    done

    if [ ${SHOW_EXP:-f} = t -o ${SHOW_LOG_FNAME:-f} = t ] ; then
      if [ ${timeCounter} -eq 50 ] ; then
        std_out ttyOnly "\r${blank}\r"
        timeCounter=0
      fi
      test ${SIMPLE_STATUS_LINE:-f} = f && std_out ttyOnly '.'
      timeCounter=$(( timeCounter + 1 ))
      sleep 1
    fi
  done

  # restore stdin and free #9
  exec 0<&9 9<&-
}

getDateRange()
{

  # echo a date interval, or an instantaneous date none
  local f r

  test $# -eq 0 && return

  f=${1%.nc}

  # e.g. extracts both 186001-186612 and 186001-186612-clim
  r=$( expr match $f '.*_\([[:digit:]]*-[[:digit:]]*.*\)' )

  if [ ! ${r} ] ; then
    # no 'appendix allowed'
    r=$( expr match $f '.*_\([[:digit:]]*\)' )
  fi

  test ${r} && echo $r

  return
}

##//! Determine experiments to be processed during this session
##/*!
## The format of experiment names is ruled by the LOG_PATH_INDEX configuration option.
##*/

getExperimentName()
{
  # find and set CURR_LOG_FNAME
  local mode=$1
  shift

  if [ ${LOG_FNAME} ] ; then
    CURR_LOG_FNAME=${LOG_FNAME:-'undefined-scope'}
  elif [ ${mode} = P ] ; then
    if ! getExperimentNameFromPath $1 ; then
      return 1
    fi
  elif [ ${mode} = F ] ; then
    getExperimentNameFromFile $1
  fi

  local iex
  for(( iex=0 ; iex < ${#LOG_FNAMES[*]} ; ++iex )) ; do
    if [ "${LOG_FNAMES[iex]}" = "${CURR_LOG_FNAME}" ] ; then
      return 0
    fi
  done

  # a new entry
  test ! "${CURR_LOG_FNAME}" && CURR_LOG_FNAME='undefined-scope'

  LOG_FNAMES[${#LOG_FNAMES[*]}]=${CURR_LOG_FNAME}

  test ! -f $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log && copyPreamble

  return 0
}

getExperimentNameFromFile()
{
  # extract the name of the experiment from subPath
  # see function initExperimentName()

  # LOG_FNAME was defined in initExperimentName() and will never be
  # changed again

  # decompose the filename
  CURR_LOG_FNAME=

  if [ ${#LOG_FILE_INDEX[*]} -gt 0 ] ; then
    local c f_items
    declare -a f_items

    local lfs=${LOG_FILE_SEPARATOR:-_}

    f_items=( ${1//${lfs}/ } )
    local N=${#f_items[*]}

    # compose the name
    for c in ${LOG_FILE_INDEX[*]} ; do
        # this allows filenames with less items than prescribed by LOG_FILE_INDEX
        test $c -lt $N && \
          CURR_LOG_FNAME=${CURR_LOG_FNAME}${CURR_LOG_FNAME:+_}${f_items[c]}
    done
  fi

  #CURR_LOG_FNAME=undefined-scope
  test ! ${CURR_LOG_FNAME} && return 1

  return 0
}

getExperimentNameFromPath()
{
  # extract the name of the experiment from subPath
  # see function initExperimentName()

  # LOG_FNAME was defined in initExperimentName() and will never be
  # changed again

  # decompose the path
  local pcs
  declare -a pcs
  pcs=${PROJECT_DATA}/$1
  pcs=( ${pcs//\// } )

  local c lpi
  declare -a lpi

  local N=${#pcs[*]}
  CURR_LOG_FNAME=

  if [ ${DRS_PATH_BASE} ] ; then
    # for multiple occurrences of the base take the last one
    local base_ix
    # case-insensitive
    local ldpb=$( echo "${DRS_PATH_BASE}" | tr "[:lower:]" "[:upper:]" )
    local lci
    for(( c=0 ; c < N ; ++c )) ; do
      lci=$( echo "${pcs[c]}" | tr "[:lower:]" "[:upper:]" )
      test "$lci" = ${ldpb} && base_ix=$c
    done

    # no anchour found
    test ! ${base_ix} && return 1

    for(( c=0 ; c < ${#LOG_PATH_INDEX[*]} ; ++c )) ; do
      lpi[c]=$(( base_ix + ${LOG_PATH_INDEX[c]} ))
    done

    # compose the name
    for c in ${lpi[*]} ; do
        # this allows paths with less items than prescribed by LOG_FILE_INDEX
        test $c -lt $N && \
          CURR_LOG_FNAME=${CURR_LOG_FNAME}${CURR_LOG_FNAME:+_}${pcs[c]}
    done
  fi

  test ! ${CURR_LOG_FNAME} && return 1

  return 0
}

getFilenameBase()
{
  # an explicit file was selected
  if [ ${explFName} ] ; then
    fBase=${explFName}
    return
  fi

  local f i j k tmp
  unset fBase

  if [ ${QUERY_EMPTY_DIR:-f} = t ] ; then
    if find ${PROJECT_DATA}/${subPath} \
          -maxdepth 1 -type d -empty | grep -q .  ; then
      if [ ${YAML:-f} = f ] ; then
        gNV_log1 $1
      else
        y_impact=L2
        y_caption="empty directory"
        y_tag=M1
        y_status=1
        nextPath=${PROJECT_DATA}/${subPath}
        gNV_Ylog 'N/A'
      fi

      return
    fi
  fi

  local fileNames
  declare -a fileNames

  if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
    fileNames=($(find ${PROJECT_DATA}/${subPath} -maxdepth 1 ! -type d -name "*"))
  else
    fileNames=($(find ${PROJECT_DATA}/${subPath} -maxdepth 1 -name "*.nc"))
  fi

  if [ ${IGNORE_BROKEN_LINKS:-f} = t ] ; then
    for(( j=${#fileNames[*]} - 1 ; j >= 0 ; --j )) ; do
      if [ -h ${fileNames[j]} -a ! -e ${fileNames[j]} ] ; then
        unset fileNames[$j]
      fi
    done
  fi

  fBase=( ${fileNames[*]#${PROJECT_DATA}/${subPath}/} )

  # find all available files: same root, but different time periods
  # is there any qa_*.nc ? Rather circuitous, but safe.
  # works also for names without appended date

  fBase=( ${fBase[*]%.nc} )

  # distinguish asd_range from asdf_range
  for(( i=0 ; i < ${#fBase[*]} ; ++i )) ; do
    tmp=$( getDateRange ${fBase[i]} )
    fBase[i]=${fBase[i]%_${tmp}}
  done

  # remove duplicates
  local sz
  sz=${#fBase[*]}
  for(( i=0 ; i < ${sz} ; ++i )) ; do
    test ${#fBase[i]} -eq 0 && continue

    for(( j=i+1 ; j < ${sz} ; ++j )) ; do
      test "${fBase[i]}" = "${fBase[j]}" && unset fBase[j]
    done
  done

  fBase=( ${fBase[*]} )

  return
}

##//! Get the name of a host ready for a start of the \a qaExecutor

##/*!
## All host must share the same file system. Names of hosts is
## supplied by the configuration option QA_EXEC_HOSTS. Maximum number of
## simultaneous qaExecutor instances is given by NUM_EXEC_THREADS.
##*/

getHost()
{
  # determination of a next host. The limits by
  # QA_EXEC_HOSTS and NUM_EXEC_THREADS are applied.

  # before that, however, check for closed message-files
  checkClosedMessages

  local loadShort load15min
  local currSec fileSec filePID xx

  local i j currHost currNum
  declare -a currNum

  if [ ${NIGHT_SHIFT:-f} = t ] ; then
    # only work at night time
    local dayTime
    dayTime=$(date +'%H')
    if [ $dayTime -lt 8 -o $dayTime -gt 18 ] ; then
      QA_EXEC_HOSTS=( ${save_QA_EXEC_HOSTS[*]} )
      NUM_EXEC_THREADS=( ${save_NUM_EXEC_THREADS[*]} )
    else
      QA_EXEC_HOSTS=( $HOSTNAME )
      NUM_EXEC_THREADS=( 1 )
    fi
  fi

  # preset
  for(( i=0 ; i < ${#QA_EXEC_HOSTS[*]} ; ++i )) ; do
    currNum[i]=0
  done

#  currSec=$( date +'%s' )  # works only for unix
  currSec=$( ${QA_BIN#*:}/unixTime.x )
  local f
  for f in $( ls -1 $PROC_POOL/*.lock 2> /dev/null ) ; do
    f=${f%.lock}

    # extract host name from the file
    currHost=${f%%:*}

    # check whether the process is old and if yes,
    # whether it is still alive

#    fileSec=$( fModTime.x $PROC_POOL/$f 2> /dev/null )
#    test ! ${fileSec} && continue  # lost the race

    # only for linux
# #   fileSec=$( ls -l --time-style=+'%s' $PROC_POOL/$line \
#              2> /dev/null |  awk '{print $6}' )


    # is file older than 2 hours?
#    if [ $(( currSec - fileSec - 7200 )) -gt 0 ] ; then
#      # is there any pending pid?
#      filePID=$( expr match $line '.*:.*:\(.*\)' )
#      if [ ${filePID} ] ; then
#         if [ "${currHost}" == "${HOSTNAME}" ] ; then
#           xx=$(ps hp $filePID)
#         else
#           xx=$(ssh $currHost ps hp $filePID)
#         fi

#         if [ ! ${xx} ] ; then
           #dead
#           \rm -f $PROC_POOL/$line   # lost the race
#           continue
#         fi
#      fi
#    fi

    # Determine the host names currently in use and
    # the number of corresponding instances of executors.
    for(( i=0 ; i < ${#QA_EXEC_HOSTS[*]} ; ++i )) ; do
      if [ "${currHost}" = "${QA_EXEC_HOSTS[i]}" ] ; then
        currNum[i]=$(( ${currNum[i]} + 1 ))
        continue 2
      fi
    done
  done

  # look for a free slot
  for(( j=0 ; j < ${#QA_EXEC_HOSTS[*]} ; ++j )) ; do
    if [ ${currNum[j]} -lt ${NUM_EXEC_THREADS[j]} ] ; then
      nextHost=${QA_EXEC_HOSTS[j]}

      # only select a host, if it is reachable
#      if ping -c 1 $nextHost &> /dev/null ; then
#      if callPing $nextHost ; then
        #only select host, if load is lower some limits
#        upTime=( $(ssh $nextHost uptime) )
#        i=$(( ${#upTime[*]} - 3 ))
#        loadShort=${upTime[i++]}
#        load15min=${upTime[++i]}

#        if [ $( echo "a=0;if(${loadShort%,} < 1.5)a=1;a" | bc -l) -eq 1 -a \
#          $( echo "a=0;if(${load15min} < 1.0)a=1;a" | bc -l) -eq 1 ] ; then

          return 0
#        fi
#      fi
    fi
  done

  # return, if maximum number of executors per host is reached
  return 1
}

##//! Get a list of sub-temporal files of a given variable.

##/*!
## Variable in the sense of CMIP5(CORDEX: name and MIP tabele/frequency.
## Linked files are treated according to the configuration option
## DEREFERENCE_SYM_LINKS. Locked variables are recognised.
##*/

getNextVariable()
{
  # $1 fBase

  # return 0, if a qa-check shall not be done(, mostly because it
  #           was already done previously), then idle.
  # return 1, if the file nextFile is going to be checked.

  # the path to the candidates of files to be checked
  nextPath=${PROJECT_DATA}/${subPath}

  countSelectedVars=$(( countSelectedVars +1 ))

  # explict file is selected
  if [ ${explFName} ] ; then
    nextFile=${explFName}
    return 1
  fi

  local ix
  local text
  local status checksumTable

  local link_filenameBase=$1

  # get files with fBase (temporal information added)
  if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
    nV_fls=( $( find -L ${nextPath} -maxdepth 1 -type f -name "${1}*" 2> /dev/null ) )
  else
    nV_fls=( $( find -L ${nextPath} -maxdepth 1 -name "${1}*.nc" 2> /dev/null ) )
  fi
  nV_fls=( ${nV_fls[*]#${nextPath}\/} )

  if [ ${#nV_fls[*]} -eq 0 ] ; then
    # empty dir was trapped before
    nextFile=  # ignore, try next
    return 0
  fi

  local num=${#nV_fls[*]}

  # check for broken symbolic links
  local f l is

  if [ ${ACCEPT_EVERY_FILE:-f} = t ] ; then
    nextFile=( ${nV_fls[*]} )
    return 1
  fi

    for(( l=${#nV_fls[*]} - 1 ; l >= 0 ; --l )) ; do
      f=$nextPath/${nV_fls[l]}
      if [ -h $f -a ! -e $f ] ; then
        if [ ${IGNORE_BROKEN_LINKS:-f} = t ] ; then
          continue
        else
          y_impact=L2
          y_caption='broken link'
          y_tag=M2
          initLog ${nV_fls[l]}

          is=t
        fi
      fi
    done
    if [ ${is:-f} = t ] ; then
      nextFile=  # ignore, try next
      return 0
    fi

    for(( l=0 ;  l < ${#nV_fls[*]} ; ++l )) ; do
      f=$nextPath/${nV_fls[l]}
      local num=${#nV_fls[*]}

      if [ ! -s $nextPath/${nV_fls[l]} ] ; then
        if [ ${QUERY_EMPTY_FILE:-f} = t ] ; then
          y_impact=L2
          y_caption='no data file'
          y_tag=M3
          initLog ${nV_fls[l]}
          unset nV_fls[${l}]
        fi

        is=t
      elif ! expr match ${nV_fls[l]} "${1}.*\.nc" &> /dev/null ; then
        if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
          y_caption="invalid filename, found ${nV_fls[l]}"
          y_impact=L1
          y_tag=M6
          initLog ${nV_fls[l]}
          unset nV_fls[${l}]
        fi

        is=t
     fi
    done
    if [ ${is:-f} = t ] ; then
      nextFile=  # ignore, try next
      return 0
    fi

    nV_fls=( ${nV_fls[*]} )

  # check read permission on each file; this must be done prior the
  # call to syncFiles.x, because no permission would cause a
  # failed ambiguity check
  local f fp
  local is=f

  for(( f=0 ; f < ${#nV_fls[*]} ; ++f )) ; do
    if [ ! -r $nextPath/${nV_fls[f]} ] ; then
      y_impact=L2
      y_caption='no permission to read netCDF file'
      y_tag=M4
      initLog ${nV_fls[l]}

      finally
    fi
  done

  # there is no warning, when all files of a given variable
  # are broken links.
  if [ ${IGNORE_BROKEN_LINKS:-f} = t -a ! ${#nV_fls[*]} -eq 0 ] ; then
    nextFile=  # ignore, try next
    return 0
  fi

  # Note: if the first attempt of creating a qa-nc file
  # was interrupted by a system crash before closing it properly,
  # then the qa-nc file is corrupt. If a crash happened at any
  # further attempt to continue writing, then there will be a
  # back-up file available. Note: return value 0 (true) would happen
  # only, if there are more than one qa-files backup files.
  # The function shall clear such.
  if checkCorruptedQA ${QA_RESULTS}/data/${subPath} $1 ; then
    nextFile=  # ignore, try next
    return 0
  fi

  # container for parameter passed to syncFiles.x
  syncOpts=$syncOptsInit

  # get name of file that has to be processed next (or none)
  local isMixingRefused=t
  if [ ${SYNC_FILE_AMBIGUITY_CHECK:-f} != f ] ; then
     local sfa
     local is
     for sfa in ${SYNC_FILE_AMBIGUITY_CHECK//,/ } ; do
       if [ ${sfa} = no_mod ] ; then
         is=f
       elif [ ${sfa} = mixed ] ; then
         syncOpts="${syncOpts} -m"
         isMixingRefused=f
       fi

       test ${is:-t} = t && syncOpts="${syncOpts} -M"
     done
  fi

  # Did checksums change?
  if [ ${CHECKSUM} ] ; then
    bind_checksum ${nV_fls[*]}
    status=$?

    # checksum has changed; remove qa results
    test $status -gt 1 && \rm ${QA_RESULTS}/data/${subPath}/qa_${1}.* 2> /dev/null

    if [ $status -eq 6 ] ; then
      # creation_date and/or tracking_id was kept
      nextFile=  # ignore, try next
      return 0
    fi
  fi

  qa_fl=$( ls ${QA_RESULTS}/data/${subPath}/qa_${1}.nc 2> /dev/null)

  # apply rules, clearings, and test for qa_note files
  if [ "${SHOW_CLEAR}" ] ; then
    clear
    nextFile=
    return 0
  fi

  if \
#trace \
    testLocks $1 qa_fl ; then
      nextFile=  # ignore, try next
      return 0
  fi

  # sync with qa_file if available
  #exception: only scan for the tracking id
  if [ "${qa_fl}" -a ${TRACKING_ID_ONLY:-f} = f ] ; then
    syncOpts="${syncOpts} -p ${qa_fl}"
  fi

  # any time limit specified?
  local tl
  test ${TIME_LIMIT} && syncOpts="${syncOpts} -l ${TIME_LIMIT}"

  if [ ${isMixingRefused} = t -a ${IGNORE_TEMP_FILES:-f} = t ] ; then
    local tf tff tfs
    declare -a tff tfs

    for tf in ${nV_fls[*]} ; do
      # exclude fixed variables from ignoring
      tff=${tf#*_}
      tff=${tff%%_*}

      if [ "${tff}" != fx ] ; then
        tff=
        tff=$( getDateRange $tf )
        test ! ${tff} && continue
      fi

      tfs[${#tfs[*]}]=$tf
    done

    nV_fls=( ${tfs[*]} )

    if [ ${#nV_fls[*]} -eq 0 ] ; then
      nextFile=  # ignore, try next
      return 0
    fi
  fi

  if [ ${NO_SEQUENCE_CHECK:-f} = t ] ; then
    nextFile=( ${nV_fls[*]} )
    return 1
  fi

#  nextFile="$(echo ${nV_fls[*]} | ${QA_BIN#*:}/syncFiles.x \
#     $syncOpts -P ${nextPath} )"
  local nxtFl

  if [ ${SHOW_SYNCFILES} ] ; then
    echo "$syncOpts -P ${nextPath} ${nV_fls[*]}"
    exit
  fi

  # get frequency from filename or path
  if [ ${FILE_NAME_FREQ_INDEX} ] ; then
     local x_fName
     declare -a x_fName

     if [ "${FILE_NAME_SEP}" = '/' ] ; then
        x_fName=( ${nV_fls[0]//\${FILE_NAME_SEP}/ } )
     else
        x_fName=( ${nV_fls[0]//${FILE_NAME_SEP}/ } )
     fi
     FREQUENCY=${x_fname[${FREQ_INDEX_FNAME}]}
  elif [ ${FREQ_INDEX_PATH} ] ; then
     local x_path
     declare -a x_path

     if [ "${PATH_SEP}" = '/' ] ; then
       x_path=( ${nextPath//\${PATH_SEP}/ } )
     else
       x_path=( ${nextPath//${PATH_SEP}/ } )
     fi
     FREQUENCY=${x_path[${FREQ_INDEX_PATH}]}
  fi
  #syncOpts="${syncOpts} --freq=${FREQUENCY}"

  nxtFl="$( ${QA_BIN#*:}/syncFiles.x \
     $syncOpts -P ${nextPath} ${nV_fls[*]} )"

  status=$?

  # expand \newline, but preserve potential blanks
  nextFile=()
  local p0 p1 i
  for(( p0=0 , p1=0 , i=0 ; p1 < ${#nxtFl} ; ++p1 )) ; do
    if [ "${nxtFl:p1:1}" == '_' -a "${nxtFl:p1:7}" == '__EOL__' ] ; then
      nextFile[i++]="${nxtFl:p0:$((p1-p0))}"
      p0=$((p1 + 7))
      p1=$((p1+6)) # because of ++p1
    fi
  done

  if [ ${SHOW_SYNC:-f} = t ] ; then
     std_out flush "${nextFile[*]/%/\\n}"
  fi

  local nFsSz=${#nextFile[*]}

  # up-to-date
  if [ ${status} -eq 1 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      # get number of data files for progress estimation
      # note: all files no matter whether processed or locked
#      local num=${#nV_fls[*]}
#    fi
    countProcessedFiles=$(( countProcessedFiles +1 ))

    nextFile=
    return 0
  fi

  if [ $status -eq 3 -o $status -eq 5 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      local num=${#nV_fls[*]}
#    fi

#    isAnythingDone=t

    y_impact=L2
    if [ $status -eq 3 ] ; then
      y_caption='syncFiles.cpp with unspecific failure'
      y_tag=M5
    else
      y_caption='file(s) with invalid time data'
      y_tag=M9
    fi

    y_meta_data=OMIT
    y_time_values=FAIL
    y_status=${status}

    for(( i=0 ; i < ${#nextFile[*]} ; ++i )) ; do
      y_text[i]=${nextFile[i]}
    done

    initLog $1

    nextFile=  # ignore, try next
    return 0
  fi

  # a fixed variable?
  if [ $status -eq 4 ] ; then
    # already processed?
    if [ "${qa_fl}" ] ; then
#      if [ ${PROGRESS_BAR} ] ; then
        # get number of data files for progress estimation
        # note: all files no matter whether processed or locked
        local num=${#nV_fls[*]}
#      fi

      nextFile=
      return 0
    fi
  fi

  # SYNC_FILE_AMBIGUITY_CHECK failed?
  if [ $status -gt 9 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      local num=${#nV_fls[*]}
#    fi

#    isAnythingDone=t

    # issue annotation
    y_impact=L2
    y_caption='syncFiles.cpp: sub-temporal file sequence ambiguities.'
    y_tag=M6
    y_meta_data=OMIT
    y_time_values=FAIL
    y_status=${status}

    for(( i=0 ; i < ${#nextFile[*]} ; ++i )) ; do
      y_text[i]=${nextFile[i]}
    done

    initLog $1

    nextFile= # ignore, try next
    return 0
  fi

  if [ ${TEST_FNAME_ALIGNMENT} ] ; then
    nextFile= # ignore, try next
    return 0
  fi

#  if [ ${DEREFERENCE_SYM_LINKS:-f} = f -a \
#        -h ${PROJECT_DATA}/${subPath}/$nextFile ] ; then
#    # make links for QA results, where links are in the DRS tree
#    # (not for links to the outside of the DRS tree).
#    testFileLink $1
#    nextFile= # ignore, try next
#    unset nV_fls
#    return 0
#  fi

  return 1
}

##//! Get sub-path to a variable scheduled next.

getNextSubPath()
{
  # subPaths from a temporary file redirected to stdin.
  local ix line
  declare -a line

  # init progress estimation
#  if [ ${PROGRESS_BAR} ] ; then
    if [ ${progressTotalAtomicNum:-0} -eq 0 ] ; then
      if [ "$(tail -n 1 ${pathListFile})" = '---EOF---' ] ; then
        progressTotalAtomicNum=$(wc -l ${pathListFile} | awk '{print $1}')
        progressTotalAtomicNum=$(( progressTotalAtomicNum -1 ))
      fi
    fi
#  fi

  # pathListFile was connected to stdin in check()
  while : ; do  # for trapping the end

  while read -a line ; do
    # return 1: fade out operation
    if [ ${line[0]} = '---EOF---' ] ; then
      unset fBase
      fBase=''
      subPath=''
      explFName=''
      END_OF_PATHS=t
      return
    fi

    progressAtomicNum=$(( ${progressAtomicNum} + 1 ))

    subPath=${line[1]}
    explFName=${line[2]}  # available only for a single file selection
    test ${line[0]} -gt -1 && PROJECT_DATA=${PROJECT_DATAV[${line[0]}]}

    # if read returned true, although there was currently no more entry
    test "${prevLine}" = "${subPath}" && break
    prevLine=${subPath}

    # find the root of all files, stripping of date-periods;
    # puts names to fBase
#trace \
    getFilenameBase

    if [ ${#fBase[*]} -gt 0 ] ; then
      # found unlocked variable (constraint: SHOW_CLEAR=f)
      mkdir -p ${QA_RESULTS}/data/${subPath}

      if [ ${waitCounter} -gt 0 ] ; then
        displayStatusLine 51 ''
        waitCounter=0
      fi

      return
    fi
  done

  # for EOF case
  # a getSelectedPath process is still running; kill it
  if ps -p ${getPathPID:-0} -o pid= &> /dev/null  ; then
    # the search for paths did not finish, yet.
    test ${waitCounter} -eq 0 && displayStatusLine 51 "."
    waitCounter=$(( waitCounter + 1 ))

    test ${waitCounter} -eq 50 && waitCounter=0

    std_out ttyOnly '.'
    sleep 1
  fi

  done

  return
}

##//! Get paths to all variables scheduled for processing.

##/*!
## The function runs in the back-ground and writes all paths found
## to a temporary file. SELECTion and LOCK assigned in the configuration
## are applied.
##*/

getPaths()
{
  test ! ${DEBUG_MANAGER} && voidX
  # if set -x enabled, then disable for this function

  # Get all paths to sub-dirs that contain netCDF file(s)
  # and list these in a temp file in the directory Project_table.

  test ${SHOW_PATH_SEARCH:-f} = t && set -x

  set -f

  # filename
  pathListFile=${SESSION_LOGDIR}/path-list.txt

  # special: only a file is provided for a single check
  if [ ! ${PROJECT_DATAV} ] ; then
     # split filename
     local fname x_pf
     declare -a x_pf
     x_pf=(${PROVIDED_FILES//,/ })

     if [ ${#x_pf[*]} -eq 1 ] ; then
       if [ ${x_pf:0:2} = './' ] ; then
         x_pf=${PWD}${x_pf:1}
         echo "-1 ${PWD} ${x_pf##*/}" > $pathListFile
       elif [ ${x_pf:0:3} = '../' ] ; then
         x_pf=${PWD%/*}${x_pf:2}
         echo "-1 ${PWD%/*} ${x_pf##*/}" > $pathListFile
       elif [ ${x_pf:0:1} != '/' ] ; then
         # relative path
         if [ ${x_pf##*/} = ${x_pf} ] ; then
            echo "-1 ${PWD} ${x_pf}" > $pathListFile
         else
            echo "-1 ${PWD}/${x_pf%/*} ${x_pf##*/}" > $pathListFile
         fi
         x_pf=${PWD}/${x_pf}
       else
         # absolute path
         echo "-1 ${x_pf%/*} ${x_pf##*/}" > $pathListFile
       fi
       echo "---EOF---" >> $pathListFile

       # assumption that there is no file on root '/'
       x_pf=${x_pf:1} # strip leading /
       PROJECT_DATAV=/${x_pf%/*}
       SELECT_VAR_LIST[0]=${x_pf##*/}
       SELECT_VAR_LIST[0]=${SELECT_VAR_LIST[0]%%_*}_
       SELECT_PATH_LIST[0]='.*'
       #SELECT_PATH_LIST[0]=${SELECT_PATH_LIST[0]%/*}=
       NO_SUMMARY=t
       unset QUERY_NON_NC_FILE
       IS_SINGLE_FILE_MODE=t
       set +f
       return
     else
       exit 1
     fi
  fi

  PROJECT_DATAV=( ${PROJECT_DATAV[*]//,/ } )

  # very special: no SELECT at all
  if [ ${#SELECT_PATH_LIST[*]} -eq 0 \
        -a ${#SELECT_VAR_LIST[*]} -eq 0 ] ; then
    local i
    for(( i=0 ; i < ${#PROJECT_DATAV[*]} ; ++i )) ; do

      if [ -f ${PROJECT_DATAV[i]} ] ; then
        # it is a file !!!
        SELECT_VAR_LIST[${#SELECT_VAR_LIST[*]}]=${PROJECT_DATAV[i]##*/}
        PROJECT_DATAV[i]=${PROJECT_DATAV[i]%/*}
        SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]=${PROJECT_DATAV[i]##*/}
        PROJECT_DATAV[i]=${PROJECT_DATAV[i]%/*}
      else
        SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]=${PROJECT_DATAV[i]##*/}
        SELECT_VAR_LIST[${#SELECT_VAR_LIST[*]}]='.*'
        PROJECT_DATAV[i]=${PROJECT_DATAV[i]%/*}

        # a directory or something with RegExpr
#        splitAtRegExp ${PROJECT_DATAV[i]}

#        if [ ! ${splitRE_1} ] ; then
#          SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]='.*'
#        else
#          SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]=${splitRE_1}
#          PROJECT_DATAV[i]=${splitRE_0}
#        fi

#        SELECT_VAR_LIST[${#SELECT_VAR_LIST[*]}]='.*'
      fi
    done
  fi

  # very special: a SELECT of a full path
  # take into account selections from outside of PROJECT_PATH,
  # i.e. such with a leading /
  for(( l=0 ;  l < ${#SELECT_PATH_LIST[*]} ; ++l )) ; do
    item=${SELECT_PATH_LIST[l]}

    for(( k=0 ; k < ${#PROJECT_DATAV[*]} ; ++k )) do
      # split selected path into components
      if [ "${item:0:1}" = '/' ] ; then
        # though absolute, it is within P_D
        test ${item} != ${item#${PROJECT_DATAV[k]}}  && continue 2
      else
        continue 2
      fi
    done

    # A selection with absolute path, which doesn't fit PROJECT_DATA.
    if [ -f $item ] ; then
      # it is a file !!!
      SELECT_VAR_LIST[l]=${item##*/}
      item=${item%/*}
      SELECT_PATH_LIST[l]=${item##*/}
      PROJECT_DATAV[${#PROJECT_DATAV[*]}]="${item%/*}"
    elif [ -d $item ] ; then
      # a directory with or without var-selection
      SELECT_PATH_LIST[${l}]=${item##*/}
      PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${item%/*}
    else #if [ ${SELECT_VAR_LIST[${l}]} != '.*' ] ; then
      # a directory with var-selection
      splitAtRegExp ${item}

      if [ ! ${splitRE_1} ] ; then
        SELECT_PATH_LIST[${l}]=${splitRE_0##*/}
        PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${splitRE_0%/*}
      else
        SELECT_PATH_LIST[${l}]=${splitRE_1}
        PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${splitRE_0}
      fi
    fi
  done

  # only those paths that are selected and contain netCDF files
  if [ ! -f ${SESSION_LOGDIR}/path-list.txt ] \
       || ! grep -q -- '---EOF---' ${SESSION_LOGDIR}/path-list.txt ; then
    \rm -f "${pathListFile}"

    if is_TPUT ; then
      echo "getPaths ... " > $TTY
    fi

    getSelectedPaths ${PROJECT_DATAV[*]} &
    getPathPID=$!
  fi

  set +f

  if [ ${SHOW_PATH_SEARCH:-f} = t ] ; then
    set +x
    wait
    exit
  fi

  # Only pass the loop when the file is already partially filled.
  # Then, it is garantueed that there will be an EOF mark.
  while : ; do
    test ! -e ${pathListFile} && continue

    while [ ! -s ${pathListFile} ] ; do
      sleep 1
    done

    break
  done


  if [ "$( head -n 1 $pathListFile)" = '---EOF---' ] ; then
    if [ ${#PROJECT_DATAV[*]} -eq 1 ] ; then
      sTxt[0]="3data_path: ${PROJECT_DATAV}"
    else
      local tt="${PROJECT_DATAV[*]}"
      sTxt[0]="3data_path: [${tt// /, }]"
    fi

    sTxt[1]="3info: 1"
    sTxt[2]="3 - no valid sub-path found in data_path"

    std_out flush "${sTxt[0]:1}\n${sTxt[2]:4}"

    sendSubject="qa-DKRZ: SELECT/LOCK conflict"

    sendEMail
    lastStatus=1  # exit status of this script
    exit
  fi

  test ! ${DEBUG_MANAGER} && voidX # roll back enabled set -x
}

getProjectTableName()
{
  # decompose the path
  local pcs
  declare -a pcs
  pcs=${PROJECT_DATA}/$1
  pcs=( ${pcs//\// } )

  # check for path component 'output'
  test ! ${DRS_PATH_BASE} && DRS_PATH_BASE=${pcs[0]}

  local countEPB=0
  local c ptPathIndex M N
  declare ptPathIndex
  N=${#pcs[*]}

  # for multiple occurrences
  local base_ix=0
  for(( c=0 ; c < N ; ++c )) ; do
    test "${pcs[c]}" = ${DRS_PATH_BASE} && base_ix=$c
  done

  local ix
  for(( ix=0 ; ix < ${#CT_PATH_INDEX[*]} ; ++ix )) ; do
    ptPathIndex[ix]=$(( base_ix + ${CT_PATH_INDEX[ix]} ))
  done

  test ${#ptPathIndex[*]} -eq 0 && ptPathIndex=( ${CT_PATH_INDEX[*]} )

  # compose the name
  PROJECT_TABLE=$PRJCT_BASENAME
  if [ ${#ptPathIndex[*]} -gt 0 ] ; then
    for c in ${ptPathIndex[*]} ; do
      if [ $c -lt $N ] ; then
        # subtract the reversed positional index from array size
        PROJECT_TABLE=${PROJECT_TABLE}${pcs[c]}_
      fi
    done
  else
    PROJECT_TABLE=unknownExp
  fi

  PROJECT_TABLE=${PROJECT_TABLE%_}

  return
}

getSelectedPaths()
{
  # descent recursively into dirs and write all sub-paths,
  # containing at least one netCDF file,
  # into a file.
  test ${SHOW_PATH_SEARCH:-f} = f && set +x

  local currDirs projectDataIndex
  declare -a currDirs projectDataIndex

  local e i j k l s

  set +f

  if [ ${isStart:-t} = t ] ; then
    isStart=f

    # first depth
    if [ ${#SELECT_PATH_LIST[*]} -eq 0 ] ; then
      SELECT_PATH_LIST=( '.*' )
      SELECT_VAR_LIST=( '.*' )
    fi

    splCount=${#SELECT_PATH_LIST[*]}
    lplCount=${#LOCK_PATH_LIST[*]}

    for(( k=0 ; k < lplCount ; ++k )) ; do
      LOCK_PATH_LIST[${k}]=".*${LOCK_PATH_LIST[k]}"
    done

    local item items sub0 sub1 projectDataPath
    declare -a items projectDataPath

    projectDataPath=( $* ) # actually PROJECT_DATA paths
    recurrCount=0

    for(( k=0 ; k < ${#projectDataPath[*]} ; ++k )) do
      isPDP_only=t

      for(( l=0 ;  l < ${splCount} ; ++l )) ; do
        # split selected path into components
        item=${SELECT_PATH_LIST[l]}
        item=${item#${projectDataPath[k]}/}
        items=( ${item//\// } )
        test "${item:0:1}" = '/' && break

        sub0=

        # look for an alpha-numeric sub-path leading a selected path
        for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
          if expr match ${items[i]} "[[:alnum:]_-]\{${#items[i]}\}" &> /dev/null ; then
            # only accept valid paths
            sub1=${sub0}/"${items[i]}"
            test ! -e ${projectDataPath[k]}$sub1 && break

            sub0=$sub1
          else
            break
          fi
        done

        if [ ${sub0} ] ; then
          isPDP_only=f
          currDirs[${#currDirs[*]}]=${projectDataPath[k]}$sub0
          basePaths[${#basePaths[*]}]=${projectDataPath[k]}
          projectDataIndex[${#projectDataIndex[*]}]=$k
        fi
      done

      if [ ${isPDP_only} = t ] ; then
        currDirs[${#currDirs[*]}]=${projectDataPath[k]}$sub0
        basePaths[${#basePaths[*]}]=${projectDataPath[k]}
        projectDataIndex[${#projectDataIndex[*]}]=$k
      fi
    done
  else
    # deeper recurrence level
    currDirs=( $* )
    recurrCount=$(( recurrCount + 1 ))
  fi

  local entries

  for(( i=0 ; i < ${#currDirs[*]} ; ++i )) ; do
    # Multiple currDirs and basePaths are only possible in the zero-th recursion level.
    # In higher levels, basePath inherits the value from the parent, when getSelected
    # was called there.
    currDir=${currDirs[i]}

    if [ ${recurrCount} -eq 0 ] ; then
      # will be inhereted in deeper recursion levels
      prjDataIndex=${projectDataIndex[i]}
      basePath=${projectDataPath[prjDataIndex]}
    fi

    entries=( $(ls -d $currDir/* 2> /dev/null) )

    if [ ${HIDDEN_DIRECTORIES:-f} = t ] ; then
      local hidden
      declare -a hidden
      hidden=( $(ls -ad $currDir/.* 2> /dev/null) )
      if [ ${#hidden[*]} -gt 2 ] ; then
        # rm . and ..
        for(( j=${#hidden[*]}-1 ; j > -1 ; --j )) ; do
          test ${hidden[j]##*/} = '.' -o ${hidden[j]##*/} = '..' \
              && unset hidden[${j}]
        done

        entries=( ${entries[*]} ${hidden[*]} )
      fi
    fi

    # check for a variable selection (which is also a directory)
    for(( s=0 ; $s < $splCount ; ++s )) ; do
      # case that a filename is appended
      if [ -f "${currDir}/${SELECT_VAR_LIST[s]##*/}" ] ; then
        # write sub-path with a leading  slash
        echo -n "${prjDataIndex} ${currDir#${basePath}/}" >> $pathListFile
        echo    " ${SELECT_VAR_LIST[s]##*/} " >> $pathListFile
        break
      fi

      if expr match "${currDir}" "${basePath}/${SELECT_PATH_LIST[s]}" &> /dev/null
      then

        for entry in ${entries[*]} ; do
          # check only netCDF files
          test -d $entry && continue

          if [ ${QUERY_ONLY_NC:-f} = t ] ; then
             test ${entry} = ${entry%.nc} && continue
          elif [ ${QUERY_ALIEN_FILE:-f} = f ] ; then
            test -d $entry -o ".${entry##*.}" != ".nc" && continue
          fi

          e=${entry##*/}

          if expr match "$e" "${SELECT_VAR_LIST[s]}" &> /dev/null
          then

            for(( l=0;  $l < $lplCount ; ++l )) ; do
              if expr match ${currDir} "${LOCK_PATH_LIST[l]}" &> /dev/null
              then
                if expr match ${e} "${LOCK_VAR_LIST[l]}" &> /dev/null
                then
                  # this dir and its descendents are locked. But,
                  # occurrence of multiple variables is possible, thus
                  # no return; just ignore this one and continue.
                  break 2
                fi
              fi
            done

            # found a valid selection; is it unique?
            if ! grep -q ${currDir#${basePath}} $pathListFile \
                  &> /dev/null ; then
              # write sub-path with a leading  slash
              echo "${prjDataIndex} ${currDir#${basePath}/}" >> $pathListFile
            fi

            # this break allows nc-files not only at the end-branches of
            # a directory structure, but also embedded.
            break 2  # only the path is needed
          fi
        done

      fi
    done

    # descend deeper
    for e in ${entries[*]} ; do
      if [ -d $e ] ; then

        # cancel entirely LOCKed directories
        for(( l=0;  $l < $lplCount ; ++l )) ; do
          if expr match ${e} "${LOCK_PATH_LIST[l]}" &> /dev/null
          then
             test "${LOCK_VAR_LIST[l]}" = '.*' && continue 2
          fi
        done

        getSelectedPaths $e
        recurrCount=$(( recurrCount - 1 ))
      fi
    done
  done

  # append End Of File mark
  test ${recurrCount} -eq 0 && echo '---EOF---' >> $pathListFile

  return
}

getSrcPath()
{
   local i items p
   declare -a items

   p=$0

   while [ -h $p ] ; do
      # resolve symbolic links: cumbersome but robust,
      items=( $(ls -l $p) )
      i=$((${#items[*]}-1))
      p=${items[i]}
   done

   # only the directory
   p=${p%/*}

   # resolve relative path
   if [ ${p:0:1} != '/' ] ; then
     cd $p &> /dev/null
     p=$(pwd)
     cd - &> /dev/null
   fi

   export QA_SRC=$p

   return
}

has()
{
  local c i j t
  declare -a c

  if [ ${1:0:7} = '--char=' ] ; then
    if [ ${#1} -eq 7 ] ; then
      c=' '
    else
      c=${1#*=}
      if [ ${#c} -gt 1 ] ; then
        t=${c}
        unset c
        for(( i=0 ; i < ${#t} ; ++i )) ; do
          c[${#c[*]}]="${t:i:1}"
        done
      fi
    fi

    shift 1
  else
    c=','
  fi

  t="$*"

  for(( j=0 ; j < ${#c[*]} ; ++j )) ; do
    for(( i=0 ; i < ${#t} ; ++i )) ; do
     test "${t:i:1}" = "${c[j]}" && return 0
   done
  done

  return 1
}


##//! Initialisation of a session

##/*!
## Starts script \a qaConfiguration.
##*/

init()
{
  # setting defaults, parsing of the configuration file and
  # command-line is left to the
  # qaConfiguration, which returns key-word assignments and lists.

  # look if argc contains a tty statement
  local is

  for(( i=1 ; i < $# ; ++i )) ; do
    test ${!i} = -x && set -x && continue
    if [ ${!i} = -T ] ; then
       i=$(( i + 1 ))
       TTY=${!i}
    fi
  done

  local T
  declare -a T

  if [ -c "$TTY" ] ; then
    T=( -T ${TTY} )
  fi

  # some defaults
  CLOSED_TTY=f
  NO_STATUS=f
  isTPUT=f

  # set QA_TABLES
  . ${QA_SRC}/scripts/getTablesPath

  if [ ${QA_EXAMPLE:-f} = t ] ; then
    initExample
  fi

  # check whether tables have been initially copied from QA_SRC to QA_TABLES;
  # if not, then do it.
  if [ ! -d $QA_TABLES/tables ] ; then
    # note that QA_TABLES is user-defined
    rsync -lrtuz --exclude='*~' $QA_SRC/tables $QA_TABLES &> /dev/null
  fi

  # note: if not --example, then example_args is empty
  basic_args=( ${example_args[*]} \
               -E_QA_SRC=${QA_SRC} \
               -E_CONFIG_FILE=${CONFIG_FILE} \
               -E_QA_TABLES=${QA_TABLES} \
               )

  callQaConfig ${T[*]} ${basic_args[*]} $*

  if disableStatusLine ; then
    if is_TTY  ; then
      if [ $NO_STATUS = f ] ; then
        if [ ${SIMPLE_STATUS_LINE:-f} = t ] ; then
          isTPUT=t
          if ! which tput &> /dev/null ; then
            isTPUT=f
          fi
        fi
      fi
    fi
  fi

  # this file indicates freezing
  . $QA_SRC/scripts/parseConfigFile UPDATE

  if [ "${UPDATE}" != frozen ] ; then
    # convert AUTO_UPDATE --> UPDATE=automatic
    if . $QA_SRC/scripts/parseConfigFile AUTO_UPDATE ; then
       . $QA_SRC/scripts/parseConfigFile UPDATE=auto
    fi

    # 'frozen' can only be disabled by install --force ...
    if [ "${CMD_UP}" = freeze ] ; then
       ${QA_SRC}/install --freeze

       CMD_UP=
       UPDATE=
    fi

    if [ ${CMD_UP} ] ; then
       test "${CMD_UP}" != t && \
          . $QA_SRC/scripts/parseConfigFile UPDATE=${CMD_UP}

       isUp=t
    elif [ ${UPDATE} ] ; then
       if [ "${CMD_UP:0:4}" = auto ] ; then
          . $QA_SRC/scripts/parseConfigFile UPDATE=auto
          isUp=t
       fi
    fi

    isInq=t

    local prj=${PROJECT}

    if [ "${installArgs}" ] ; then
      local iA_args iA_arg
      declare -a iA_args
      iA_args=(${installArgs//,/ })

      for iA_arg in ${iA_args[*]} ; do
        if [ ${iA_arg:0:2} != '--' ] ; then
          prj=${iA_arg}
          break
        fi
      done
    fi
  fi

  if [ ${isUp} ] ; then
    # checksum of current qa-dkrz
    local md5_0
    md5_0=$( md5sum ${QA_SRC}/scripts/qa-dkrz | awk '{print $1}' )

    if ${QA_SRC}/install ${TTY:+-T } ${TTY} ${INSTALL_ARGS//,/ } ${prj} ; then

        local md5_1
        md5_1=$( md5sum ${QA_SRC}/scripts/qa-dkrz | awk '{print $1}' )

        test ${md5_0} != ${md5_1} && \
            exec ${QA_SRC}/scripts/qa-dkrz ${initial_params[*]}

    else
       test $? -eq 41 & exit  # silently

       # could not make the executable for the given project
       std_out flush "could not install ${prj}"
       exit 1
    fi

    test ! ${PROJECT} && exit 0

  elif [ ${isInq} ] ; then
      if ! . $QA_SRC/scripts/inqRunEnv --read-only ${prj} ; then
        # get the state of the current installation: read config-file
        #local installArg
        #if [ ${INSTALL_ARGS} ] ; then
        #   installArg="${INSTALL_ARGS}up${prj:+,${prj}}"
        #else
        #   installArg="up${prj:+,${prj}}"
        #fi

        local p=${0%/*}
        echo -e "\nMissing external tables/executabels."  > $TTY
        echo "Please, run: ${p%/*}/install up PROJECT"  > $TTY
        exit 1
      fi

      if [ ! ${PROJECT} ] ; then
         if [ ${#SELECT_PATH_LIST} -gt 0 -o ${#SELECT_VAR_LIST} -gt 0 ] ; then
     echo "PROJECT name is required in a QA_CONF file or on the command-line."
            exit 1
         fi
      fi
  fi

  test ${STOP_AFTER_INSTALL} && exit 0

  # expand comma-sep-list to arrays
  EMAIL_SUMMARY=( ${EMAIL_SUMMARY//,/ } )
  EMAIL_TO=( ${EMAIL_TO//,/ } )
  QA_BIN=( ${QA_BIN//,/ } )
  QA_EXEC_HOSTS=( ${QA_EXEC_HOSTS//,/ } )
  NUM_EXEC_THREADS=( ${NUM_EXEC_THREADS//,/ } )

  if [ ${ONLY_SUMMARY:-f} != f -a ${isShow:-f} = f ] ; then
    # only summary of provided logfile names with absolute path
    if [ ${LOG_FNAMES} ] ; then
      LOG_FNAMES=( ${LOG_FNAMES//,/ } )
      annot_summary
      exit
    fi
  fi

  if [ "${PROJECT}" = NONE ] ; then
    std_out flush "PROJECT option is missing"
    exit 1
  fi

  # set defaults
  test ${ZOMBIE_LIMIT:-f} = f && ZOMBIE_LIMIT=3600

  # shut down any console messaging
  if [ ${QUIET:-f} = t ] ; then
    CLOSED_TTY=t
  fi

  if [ ${CHECKSUM:-f} = f ] ; then
    test "${CS_STAND_ALONE}" -o "${CS_DIR}" && CHECKSUM=t
  fi

  # parse REATTEMPT_LIMIT and SLEEP_TIME
  intTryComRepeat

  # Are the executables in QA_BIN applicable?
  if ! ${QA_BIN#*:}/unixTime.x &> /dev/null ; then
    sTxt[0]="3info: 1"
    sTxt[1]="3 - no executables in ${QA_BIN}"

    std_out flush "${sTxt[0]:1}\n${sTxt[1]:4}"
    sendEMail

    if is_TPUT ; then
      tput cuu 1 > $TTY
      tput dl 1 > $TTY
    fi

    finally
  fi

  # convert special characters to escaped ones.
  local i

#  set -f
  maxNumExecThreads=0
  local nET
  for nET in ${NUM_EXEC_THREADS[*]} ; do
    maxNumExecThreads=$(( maxNumExecThreads + nET ))
  done

  if [ "${SHOW_CLEAR}" ] ; then
    # precedence of any CLEAR assignment
#     test ${CLEAR:-f} = f -o "${CLEAR}" = t && CLEAR="${SHOW_CLEAR}"
    SHOW_CLEAR=t
  fi

  initProjectTableName

  initTables

  # save the configuration and init the session logfile
  logConfiguration $*

  local pidFile=${SESSION_LOGDIR}/pid.$rootPID

  if [ ${SHOW_CALL:-f} = f ] ; then
    # file pid.$$ contains three lines:
    # 1) path to dir where this process was started.
    # 2) the command line arguments to start plus PID of this.
    # 3) the current session path and logfile name
    tryCom \
    echo "$(pwd)"             > $pidFile
    tryCom \
    echo -n "$*"             >> $pidFile
    tryCom \
    echo " --fpid $rootPID"  >> $pidFile
    tryCom \
    echo "$SESSION_LOGDIR/session.log" >> $pidFile
  fi

  maxSleep=1  # maximum duration of incremented sleep periods

  # temporary directory for exchanges between manager and executor
  PROC_POOL=$SESSION_LOGDIR/ProcPool

  if ! mkdir -p ${PROC_POOL} &> /dev/null ; then
    sTxt[0]= "3info: 1"
    sTxt[1]= "3 - could not mkdir PROC_POOL=${PROC_POOL}"

    std_out flush "${sTxt[2]:4}"

    sendSubject="could not mkdir PROC_POOL"
    sendEMail

    lastStatus=2  # exit status of this script
    exit
  fi

  # sub-dirs for temporary session- and experiment log-files
  tryCom \
  mkdir -p ${PROC_POOL}/session &> /dev/null
  tryCom \
  mkdir -p ${PROC_POOL}/experiments &> /dev/null

  # initialisation of the indexes of DRS tokens for the experiment name
  initExperimentName

  if [ ${ONLY_SUMMARY:-f} != f -a ${isShow:-f} = f ] ; then
     if [ ${ONLY_SUMMARY} = t ] ; then
       getPaths
       getAllExps
     else
       #  ONLY_SUMMARY = all; look above for provided logfiles
       LOG_FNAMES=( $(ls -d ${QA_RESULTS}/check_logs/*.log) )
       LOG_FNAMES=( ${LOG_FNAMES[*]##*/} )
     fi

     annot_summary
     exit
  fi

  # identifier for semaphore file (incremented)
  EX_ID=$rootPID  # just a starting point

  # get all selected, non-locked paths
  getPaths

  # reassure that TTY is still valid
  if [ ${ONLY_SUMMARY:-f} = f ] && is_TPUT ; then
    tput cuu 1 > $TTY
    tput dl 1 > $TTY
  fi

  syncOptsInit='--only-marked --line-feed=__EOL__'

  # only test the time alignment by means of times in the filename;
  # no further processing of the current files
  if [ ${TEST_FNAME_ALIGNMENT} ] ; then
    syncOptsInit="${syncOptsInit} --fname-alignment --continuous"
  fi


  # progress bar
#  if [ ${PROGRESS_BAR:-f} = t ] ; then
    # write to stdout
  if [ ${PROGRESS_BAR} ] ; then
    # (over)write to a file and set percentage stepping
    local pb pbs
    declare -a pbs
    pbs=( ${PROGRESS_BAR//,/ } )

    for pb in ${pbs[*]} ; do
      if expr match ${pb} '.*[[:alpha:]]' &> /dev/null ; then
        progressFile=" >> ${pb}"
      fi
      if ! expr match ${pb} '.*[[:alpha:]]' &> /dev/null ; then
        progressStep=$pb
      fi
    done

    test ! ${progressStep} && progressStep=1  # %
    progressNext=$progressStep
  else
    progressStep=1  # %
    progressNext=1
  fi

  test ${USE_STRICT:-f} = t -a ! "${CHECKSUM}" && CHECKSUM=t

  fileCount=0 # counter for NEXT
  countLockedVars=0
  countSelectedVars=0
  countProcessedFiles=0
}

initExperimentName()
{
  # provided LOG_FNAME has preference
  if [ ${LOG_FNAME} ] ; then
    unset LOG_FNAME_PATTERN
    unset LOG_PATH_INDEX
    return
  fi

  if [ ${LOG_PATH_INDEX} ] ; then
    # extract the name of the experiment from subPath
    # Explanation: look for LOG_PATH_INDEX in a configuration file

    # we need a real array
    LOG_PATH_INDEX=( ${LOG_PATH_INDEX//,/ } )
  fi

  if [ ${LOG_FILE_INDEX} ] ; then
    # extract the name of the experiment from subPath
    # Explanation: look for LOG_PATH_INDEX in a configuration file

    # we need a real array
    LOG_FILE_INDEX=( ${LOG_FILE_INDEX//,/ } )
  fi

  if [ ! \( "${LOG_PATH_INDEX}" -o "${LOG_FILE_INDEX}" \) ] ; then
    LOG_FNAME='undefined-scope'
  fi

  return
}

##//! Init annotation logging

initLog()
{
  sTxt[$((ix++))]="3file: $1"
  sTxt[$((ix++))]="3data_path: ${nextPath}"
  sTxt[$((ix++))]="3result_path: ${QA_DATADIR}/${subPath}"
  sTxt[$((ix++))]="3conclusion: FAIL"
  sTxt[$((ix++))]="3events:"
  sTxt[$((ix++))]="3 - event:"
  sTxt[$((ix++))]="7annotation: \'${y_caption}\'"
  sTxt[$((ix++))]="7impact: ${y_impact}"
  sTxt[$((ix++))]="7tag: \'${y_tag}\'"

  y_meta_data=
  y_time_values=
  y_data=

  local i
  if [ "${y_text[0]}" ] ; then
    sTxt[$((ix++))]="7info:"
    for(( i=0 ; i < ${#y_text[*]} ; ++i )) do
      sTxt[$((ix++))]='7 - '"${y_text[i]}"
    done
    unset y_text
  fi

  sTxt[$((ix++))]="3status: ${y_status:-0}"
  y_status=

  local out=${QA_RESULTS}/data/${subPath}/qa_lock_${1}.txt
  echo "Path: ${nextPath}"                  > $out
  echo "File: ${1}"                        >> $out
  echo "${impact}-${tag}: ${y_caption}" >> $out

  log

  sendSubject="Annotation: ${y_caption}"
  sendEMail
}

##//! Determination of various tables for the QA.

##/*!
## At the very first start, the script puts user-provided tables
## into QA_RESULTS/tables which are used during the further session.
##*/

initProjectTableName()
{
  if [ ${PROJECT_TABLE_PREFIX} ] ; then
    local sz=${#PROJECT_TABLE_PREFIX}
    test ${PROJECT_TABLE_PREFIX:$((sz-1)):1} != '_' && \
       PROJECT_TABLE_PREFIX=${PROJECT_TABLE_PREFIX}_
  fi

  if [ ! ${PROJECT_TABLE} ] ; then
    # generate default name
    test ! ${PROJECT_TABLE_PREFIX} && PROJECT_TABLE_PREFIX=pt_

    test ! ${CT_PATH_INDEX} && PROJECT_TABLE=${PROJECT}
  fi

  PRJCT_BASENAME=${PROJECT_TABLE_PREFIX}${PROJECT_TABLE}

  return
}

initTables()
{
  # extract the name of the experiment from subPath
  # Explanation: look for LOG_PATH_INDEX in a configuration file

  # we need a real array
  CT_PATH_INDEX=( ${CT_PATH_INDEX//,/ } )

  CT_PATH_INDEX_MAX=100  # exceeds any number of path components

  if [ ${CT_PATH_INDEX[0]} ] ; then
    # note: the highest number points to the most left-side
    # path component
    CT_PATH_INDEX_MAX=0

    local t
    for t in ${CT_PATH_INDEX[*]} ; do
      test ${t} -gt ${CT_PATH_INDEX_MAX} && CT_PATH_INDEX_MAX=${t}
    done
  fi

  mkdir -p ${TABLE_PATH}
  export TABLE_PATH

  # Precedence of path search for tables:
  #
  #   tables/${PROJECT_VIRT}
  #   tables/${PROJECT}
  #   tables/projects/${PROJECT}

  # 1) default tables are provided in QA_SRC/tables/projects/PROJECT
  # 2) do not edit default tables; they are overwritten by updates
  # 3) Option TABLE_AUTO_UPDATE would search for updates for projects/PROJECT
  # 4) option USE_STRICT discards non-default tables.


  # default tables   --chmod=Du+rwx
  rsync --copy-links -lrtz \
     --exclude='*~' --exclude='.*' --exclude='*_qa.conf' \
     --exclude='IS-ENES-Data.github.io' \
     ${QA_TABLES}/tables/projects/${PROJECT}/* ${TABLE_PATH}

  if [ "$PROJECT" != CF ] ; then
    rsync -lrtuz --exclude='*~' --exclude='.*' \
       ${QA_TABLES}/tables/projects/CF/* ${TABLE_PATH}

    export CF_AREA_TYPES=${CF_AREA_TYPES}
    export CF_STANDARD_NAMES=${CF_STANDARD_NAMES}
    export CF_STD_REGION_NAMES=${CF_STD_REGION_NAMES}
    export CF_CHECK_LIST=${CF_CHECK_LIST}
  fi

  local name tc
  local tables keys
  declare -a tables keys
  for tc in ${tableCandidates[*]} ; do
    test $tc = TABLE_PATH && continue
    eval name=\$${tc}
    test ${name} = t && continue

    if expr match $name '^[a-zA-Z0-9\._-]*$' &> /dev/null ; then
       tables[${#tables[*]}]=$name  # still a candidate
       keys[${#keys[*]}]=${tc#*=}
    fi
  done

  local i prj_from prj_to
  local pDir
  declare -a pDir

  prj_to=${PROJECT}
  for(( i=0 ; i < ${#keys[*]} ;  ++i )) ; do
     # for genuine projects
     cpTables ${keys[i]} ${tables[i]} ${tables[i]} $prj_to $prj_to
  done

  if [ ${PROJECT_VIRT} ] ; then
     prj_from=${PROJECT_VIRT}

     # find corresponding tables in the virtual project
     local vTables vKeys
     declare -a vTables vKeys

     local pHT=${QA_TABLES}/tables/$prj_from

     for(( i=0 ; i < ${#keys[*]} ;  ++i )) ; do
        eval name=\$${keys[i]}
        test ${name} = t && continue

        if [ -f $pHT/${name/${prj_to}/${prj_from}} ] ; then
            vTables[${#vTables[*]}]=${name/${prj_to}/${prj_from}}
            vKeys[${#vKeys[*]}]=${keys[i]}
        elif [ -f $pHT/${name} ] ; then
            vTables[${#vTables[*]}]=$name
            vKeys[${#vKeys[*]}]=${keys[i]}
        fi

     done

     pDir=()
     for(( i=0 ; i < ${#vKeys[*]} ;  ++i )) ; do
        # map virtual prjf to the genuine project\'s table name
        local j
        for(( j=0 ; j < ${#keys[*]} ; ++j )) ; do
          test ${keys[j]} = ${vKeys[i]} && break
        done

        cpTables ${vKeys[i]} ${vTables[i]} ${tables[j]} $prj_from $prj_to
     done
  fi

  return
}

##//! Initialisation of the command launcher

intTryComRepeat()
{
  # parse REATTEMPT_LIMIT and SLEEP_TIME

  local rLs
  declare -a rLs
  rLs=( ${REATTEMPT_LIMIT//,/ } )
  unset REATTEMPT_LIMIT

  local period
  declare -a period

  for(( i=0 ; i < ${#rLs[*]} ; ++i )) do
    # two figures?
    local j perd rL

    rL=${rLs[i]}
    perd=0
    for(( j=0 ; j < ${#rL} ; ++j )) ; do
      case ${rL:$j:1} in
        s) perd=${rL:0:j}
           break ;;
        m) perd=$( echo "${rL:0:j} * 60" | bc -l )
           break ;;
        h) perd=$( echo "${rL:0:j} * 3600" | bc -l )
           break ;;
        d) perd=$( echo "${rL:0:j} * 86400" | bc -l )
           break ;;
        w) perd=$( echo "${rL:0:j} * 604800" | bc -l )
           break ;;
        M) perd=$( echo "${rL:0:j} * 2592000" | bc -l )
           break ;;
        y) perd=$( echo "${rL:0:j} * 31536000" | bc -l )
           break ;;
        \?) ;; # not valid; ignore
      esac
    done

    period=( ${period[*]} $perd )
  done

  # defaults
  SLEEP_TIME=1
  REATTEMPT_LIMIT=0
#  period[0]=${period[0]%.*}  # int-rounding

  if [ ${#period[*]} -eq 2 ] ; then
    if [ "${period[1]}" = '0' ] ; then
      SLEEP_TIME=${rLs[1]}
    else
      SLEEP_TIME=${period[1]}
    fi
  fi

  if [ ${#period[*]} -gt 0 ] ; then
    if [ "${period[0]}" = '0' ] ; then
      REATTEMPT_LIMIT=${rLs[0]}  # integer
    else
     if [ $(echo "a=0;if(${period[0]} > $SLEEP_TIME)a=1;a" | bc -l) \
           -eq 1 ] ; then
       REATTEMPT_LIMIT=$( echo "${period[0]} / $SLEEP_TIME" | bc -l)
     else
       REATTEMPT_LIMIT=$( echo "$SLEEP_TIME / ${period[0]}" | bc -l)
     fi

     REATTEMPT_LIMIT=${REATTEMPT_LIMIT%.*}
     test ! ${REATTEMPT_LIMIT} && REATTEMPT_LIMIT=0
    fi
  fi
}

##//! Inquire available disk-space

inqDiskSpace()
{
  test ${DISABLE_INQ_DISK_SPACE:-f} = t && return

  local usedDiskSpace isSubmitted

  # diskUsage.x outputs percentage of used disk space.
  # if this could not be calculated, then return silently
  if ! usedDiskSpace=$( diskUsage.x ${QA_RESULTS} ) ; then
    return
  fi

  # The used disk space must not exceed this threshold %.
  local threshold
  threshold=95

  local total used val

  while : ; do
    # disk has enough space to go on
    test $(echo "a=0;if($usedDiskSpace < $threshold )a=1;a" | bc -l ) -eq 1 && return

    if [ ${isSubmitted:-f} = f ] ; then
      sendSubject="not enough space left on device"

      local text
      text="Available capacity on device below $((100 - threshold)) %"
      text="${text}\ndf  ${QA_RESULTS}:"
      text="${text}\n$( df -h .|head -n 1)"
      text="${text}\n$( df -h .|tail -n 1)"
      text="${text}\nqa-DKRZ stays in a wait loop."

      std_out flush "${text}"
      isSubmitted=t
    fi

    sleep 91
  done

  sendSubject="disk space shortage cleared"
  text="Disk space shortage cleared."
  text="${text}\nqa-DKRZ resumes processing."

  std_out flush "${text}"
}

is_TPUT()
{
  test ${CLOSED_TTY} = t && return 1
  test $isTPUT = f      && return 1

  # reassure that TTY is still valid
  if [ ! -c "$TTY" ] ; then
    CLOSED_TTY=t
    isTPUT=f
    return 1
  fi

  return 0
}

is_TTY()
{
  test ${CLOSED_TTY} = t && return 1

  # reassure that TTY is still valid
  if [ ! -c "$TTY" ] ; then
    CLOSED_TTY=t
    return 1
  fi

  return 0
}

##//! Save configuration information.

logConfiguration()
{
  # don't create log-files
  test ${isShow:-f} = t && return

  # two things happen here. The config file(s), i.e. also a task file,
  # will be copied to the config directory.
  # Also, the names will be noted  in the session log-file, additionally
  # with the command-line call

  # when a session is resumed
  test -e ${SESSION_LOGDIR}/session.prmbl && return

  # a preamble will be copied to all log-files
  local preamble=${SESSION_LOGDIR}/session.prmbl

  if [ ${preamble} = '/session.prmbl' ] ; then
    echo "Did you provide a '-f task-file' or at least a PROJECT=name?"
    exit 1
  fi

  # this file is prepended to all exp-log-files
  tryCom \
  echo    '---'                 > $preamble
  echo    '# Log-file of a QA session started by qa-DKRZ' \
                               >> $preamble
  echo    'configuration: '    >> $preamble
  echo -n ' command-line: '    >> $preamble
  echo    "$*"                 >> $preamble

  # save living configuration options
  echo -e ' options: '      >> $preamble

  local i z
  for(( i=0 ; i < ${#keyWordList[*]} ; ++i )) ; do
     eval w="\${${keyWordList[i]}[*]}"
     test -z "$w" && w=t

     echo -n "  ${keyWordList[i]}: " >> $preamble
     if has --char=, "${w}" ; then
       echo "[${w//,/, }]"   >> $preamble
     else
       echo "${w}"           >> $preamble
     fi
  done

  # start: and corresponding date:
  log --start

  # make a link between session logdir and task name
#  if [ ${qaCs} ] ; then
#    local p s
#    p=${SESSION_LOGDIR%/*}
#    s=${SESSION_LOGDIR##*/}
#    ln -sf ${SESSION} $p/${qaCs[0]##*/}
#  fi

  return
}

##//! Log annotations to the experiment-logfile
log()
{
  # print execution messages to the experiment-log file

  local s_out  # collects sTxt for output

  local sp
  declare -a sp

  sp[0]=''
  sp[1]=' '
  sp[2]='  '
  sp[3]='   '
  sp[4]='    '
  sp[5]='     '
  sp[6]='      '
  sp[7]='       '
  sp[8]='        '

  if [ "$1" = '--start' ] ; then
    QA_REVISION="$(${QA_SRC}/scripts/getVersion ${DEBUG_MANAGER:+--debug} ${PROJECT})"

    s_out="start:\n${sp[1]}date: $( date +'%FT%T' )"
    s_out="${s_out}\n${sp[1]}qa-revision: ${QA_REVISION}"
    echo -e "$s_out" >> ${SESSION_LOGDIR}/session.prmbl

    cp ${SESSION_LOGDIR}/session.prmbl ${SESSION_LOGDIR}/session.log

    echo 'items:' >> ${SESSION_LOGDIR}/session.prmbl
    unset sTxt
    return
  fi

  local out
  if [ ${LOG_PATH_INDEX[0]} ] ; then
    if ! getExperimentName P ${subPath} ; then
      getExperimentName F ${netxFile[0]}
    fi
  else
    getExperimentName F ${netxFile[0]}
  fi
  out=$LOG_FNAME_DIR/${CURR_LOG_FNAME}.log

  s_out="${s_out} - date: $( date +'%FT%T' )"

#  if [ ${QA_HOST} = $HOSTNAME ] ; then
#  test ${ix} -lt 2 && \
#    echo  "${sp[ix]}date: $( date +'%FT%T' )" >> $out
#  else
#    tryRemote ssh ${QA_HOST} \
#      echo -e ${str} >> $out
#  fi

  # The total output is subdivided into chunks of pmax characters.
  # Effect of \n is preserved.
  local i k str0 str
  local N=70

  for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
    #sTxt: 'I[ - ]text'
    #       ^-- number of leading spaces

#    if [ "${sTxt[i]}" != "${sTxt[i]//:/}" -o ${#sTxt[i]} -lt $N ] ; then
      s_out="${s_out}\n${sp[${sTxt[i]:0:1}]}${sTxt[i]:1}"
      continue
#    fi

    # break a long text into several line
    s_out="${s_out} |"  # preserve lines

    if [ "${sTxt[i]:1:3}" = ' - ' ] ; then
      s_out="${s_out}\n${sp[${sTxt[i]:0:1}]} - |"
      str0="${sTxt[i]:4} }"
    fi

    str=

    while : ; do
      k=0  # necessarily outside the for-loop if the latter is skipped

      if [ ${#str0} -ge $N ] ; then
        # break lines with length > N
        for (( ; k < N ; ++k )) ; do
          if [ "${str0:k:2}" = "\n" ] ; then
            str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:k}\n"
            str0=${str0:$((k+2))}
            continue 2
          fi
        done
      fi

      if [ $k -eq $N ] ; then
        str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:N}\n"
        str0=${str0:N}
      else
        str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:N}"
        break
      fi
    done
    s_out="${s_out}${str}"

  done

  echo -e "${s_out}" >> $out

  test "$1" == '--keep' && return

  unset sTxt

  return
}

log_expMessage()
{
  # print execution messages to the experiment-log file

  # $1: "time-range"
  # $2: "execution message"

  local str

  # extracted name of the experiment from SUB_PATH;
  # see configuration file

  # date and time range
  str="\n$( date +'%F %T' ) "
  str="$str""$1"

#  if [ ${QA_HOST} = $HOSTNAME ] ; then
    tryCom \
    echo -e "${str}" >> $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log
#  else
#    tryRemote ssh ${QA_HOST} \
#      echo -e ${str} >> $LOG_FNAME_DIR/${CURR_LOG_FNAME}.log
#  fi

   return
}

##//! Log annotation to the session-logfile

log_sessMessage()
{
  # print messages to the log file

  test ! ${DEBUG_MANAGER} && voidX

  # date and host
  local k N str0 str

  str0="$( date +'%F %T' ) ${HOSTNAME%%.*}:qa-DKRZ\n"
  str0="${str0}$*"

  # The total output is subdivided into chunqks of pmax characters.
  # Effect of \n is preserved.
  local N
  N=100
  str=

  while : ; do
    k=0  # necessary when skipping the loop

    if [ ${#str0} -ge $N ] ; then
      # break lines with length > N
      for (( ; k < N ; ++k )) ; do
        if [ "${str0:k:2}" = "\n" ] ; then
          str="${str}${str0:0:k}\n"
          str0=${str0:$((k+2))}
          continue 2
        fi
      done
    fi

    if [ $k -eq $N ] ; then
      str="${str}${str0:0:N}\n\t"
      str0=${str0:N}
    else
      str="${str}${str0:0:N}"
      break
    fi
  done

  tryCom \
  echo -e "\n${str}" >> $SESSION_LOGDIR/session.log

  test ! ${DEBUG_MANAGER} && voidX
  return
}

##//! Log current QA version information

mkLinks()
{
  local dest_path=$1
  local subPath=$2
  local src_filename=$3
  local fBase=$4

  local i f grfs grf text text2 tmp
  declare -a grfs

  tmp=$( getDateRange ${src_filename} )
  f=${src_filename%.nc}
  f=${f%_${tmp}}

  # Get all names of corresponding genuine qa result files.
  grfs=(
     $(ls ${dest_path}/${subPath}/*${fBase}* \
         2> /dev/null) )

  local is

  tmp=$( getDateRange ${link_filenameBase} )
  link_filenameBase=${link_filenameBase%.nc}
  link_filenameBase=${link_filenameBase%_${tmp}}

  # target and link share the same filename base
  test ${link_filenameBase} = ${f} && is=t

  for grf in ${grfs[*]} ; do
    local name=${grf##*/}

    if [ ${is:-f} = t ] ; then
      test -h ${dest_path}$saveSubPath/$name && continue

      if ln -s -t ${dest_path}$saveSubPath \
            ${link_target_path}/$name &> /dev/null ; then
        text2="${text2}\nQA File:\t${grf##*/}"
      fi
    else
      grf=${grf##*/}
      grf=${grf/${f}/${link_filenameBase}}

      test -h ${dest_path}$saveSubPath/$grf && continue

      cd ${dest_path}$saveSubPath &> /dev/null
      if ln -s ${link_target_path}/$name $grf &> /dev/null ; then
        text2="${text2}\nQA File:\t${grf}"
      fi
      cd - &> /dev/null
    fi
  done

  if [ ${grfs[0]} ] ; then
    sTxt[0]="3data_path: ${PROJECT_DATA}${saveSubPath}"
    sTxt[1]="3annotation: 'symbolic link to QA results'"
    sTxt[2]="3info: $((${#grfs[*]}+2))"
    sTxt[3]="3 - qa_linkpath= ${dest_path}${saveSubPath}"
    sTxt[4]="3 - qa_target_path= ${grf[0]%/*}"

    if [ ${#grfs[*]} -gt 1 ] ; then
      local l
      for(( l=0 ; l <  ${#grfs[*]} ; ++l )) ; do
         sTxt[$((l+4))]="3 - qa_file= ${grfs[l]}"
      done
    else
      sTxt[4]="3 - qa_file= ${grfs}"
    fi

    local k n text
    for(( k=0 ; k < ${#sTxt[*]} ; ++k )) ; do
      n=1
      test "${sTxt[k]:1:3}" = ' - '  && n=4

      text="${text}${sTxt[k]:n}\n"
    done
    std_out flush "${text}"
  fi

  return
}

##//! Operate sets of sub-temporal files for a given variable.

##/*!
## Maximum number of sets is equivalent to the number of NUM_EXEC_THREADS.
##*/

operatePipes()
{
  # Variables, i.e. the entire sets of sub-temporal files,
  # are kept in a container (array of indirect references).
  # Maximum number of indirect references equals the maximum
  # of allowed number of execution threads. In the initial phase
  # the container is filled step by step for each call of this
  # function. If all sub-temporal files of a given variable
  # are processed, then the corresponding container item is
  # released and filled with the next variable. Special care
  # has to be taken when the last item of the set of sub-temporal
  # files as well as the last variable.

  local subPath
  local retVal=1

  if [ $# -gt 0 ] ; then
     subPath=$1
  else
    # drain pipes
    nFcurr=0
    retVal=0
  fi

  # empty subPath for draining the pipes; nothing to refill
  if [ ${subPath} ] ; then
    # find the next file(s); if there is any.
    if \
#trace \
      getNextVariable ${fBase[ix]} ; then

      return $retVal # try for a next one
    fi

    # Any duplicates of variables in case of multiple PROJECT_DATA
    # assignments? Note: all sub-paths are mapped to the same QA_RESULTS
    if [ ${#PROJECT_DATAV[*]} -gt 1 ] ; then
      local k;
      for(( k=0 ; k < nFmax ; ++k )) ; do
        if [ "${fBase[ix]}" = "${nF_name[k]}" ] ; then
          # The if-clause is sufficient. Testing sub-paths allows identical
          # variable names in different sub-paths (not CMIP5 or CORDEX).
          test "${fBase[ix]}" = ${nF_name[k]} && return 0
        fi
      done
    fi

    # update container of indirect references of string arrays.
    # init: direct to new pipes step by step
    # op:   redirect to drained pipes
    local j
    if [  $nFmax -lt ${maxNumExecThreads} ] ; then
      # init:
      nF_PID[${nFmax}]=0
      j=$nFmax
      nFmax=$((nFmax+1))
      nFcurr=$((nFcurr + 1 ))
    else
      # op:
      j=$nFcurr
    fi

    xyz=nFstore${j}
    eval ${xyz}=\(\${nextFile[*]}\)
    eval nFstore[${j}]=${xyz}

#trace \
    if [ ${LOG_PATH_INDEX[0]} ] ; then
      if ! getExperimentName P ${subPath} ; then
        getExperimentName F ${nextFile[0]}
      fi
    else
      getExperimentName F ${nextFile[0]}
    fi

#trace \
    if [ ${#LOG_PATH_INDEX[*]} -gt 0 ] ; then
      getProjectTableName ${subPath}
    else
      getProjectTableName ${fs[0]}
    fi

    nF_EXP[${j}]=$CURR_LOG_FNAME
    nF_TP[${j}]=$PROJECT_TABLE
    nF_SUBPATH[${j}]=${subPath}
    nF_name[${j}]=${fBase[ix]}

    if [ "${qa_fl}" ] ; then
      nF_SEQ[${j}]=s
    else
      nF_SEQ[${j}]=f
    fi
  fi

  # purpose of this loop: when all allowed execution threads
  # are busy, then wait until any of them is free again
  local op_nap=1
  local host_nap

  while : ; do
    # the index holds the value across the function
    test ${nFcurr} -eq ${nFmax} && nFcurr=0
    test ${END_OF_PATHS} && nFcurr=0

    for((  ; nFcurr < nFmax ; ++nFcurr )) ; do
      # skip pipe with a running job
      if [ ${nF_PID[nFcurr]} -gt 0 ]  ; then
        if ps -p ${nF_PID[nFcurr]} -o pid= &> /dev/null  ; then
          # the current pipe is busy
          continue
        fi
      fi

      metaV=${nFstore[nFcurr]}[*]
      metaW=${nFstore[nFcurr]}

      if [ ! ${metaW} ] ; then
         p_nF=()
      else
         p_nF=(${!metaV})
      fi
      
      CURR_LOG_FNAME=${nF_EXP[nFcurr]}
      PROJECT_TABLE=${nF_TP[nFcurr]}

      subPath=${nF_SUBPATH[nFcurr]}

      # anything extraordinary in a record of a sub-temporal file must stop
      # the pipe; p_nF -eq 0 means that the pipe is empty
      ls ${QA_RESULTS}/data/${subPath}/qa_lock_*.txt &> /dev/null
      local sts=$?

#      if [ ${sts} -eq 0 ] ; then
        # no processing due to a lock-file
#        if [ ${PROGRESS_BAR} ] ; then
#          local num=${#p_nF[*]}
#        fi
#      fi

      if [ ${#p_nF[*]} -eq 0 -o ${sts} -eq 0 ] ; then
        nF_EXP[${nFcurr}]=
        nF_TP[${nFcurr}]=
        nF_name[${nFcurr}]=
        nF_PID[${nFcurr}]=0
        nF_SUBPATH[${nFcurr}]=
        nF_SEQ[${nFcurr}]=
        unset nFstore[${nFcurr}]

        if [ ${END_OF_PATHS} ] ; then
          isDrainedPipe[${nFcurr}]=t
          continue;  # going for pipes still running
        else
          return $retVal # get next variable
        fi
      fi

      nextFile=${p_nF[0]}
      countProcessedFiles=$(( countProcessedFiles +1 ))

      if [ ${nF_SEQ[${nFcurr}]} = 'f' ] ; then
        if [ ${#p_nF[*]} -eq 1 ] ; then
          FILE_SEQUENCE=x # there is only a single file
        else
          FILE_SEQUENCE=f
          nF_SEQ[${nFcurr}]=s
        fi
      elif [ ${#p_nF[*]} -eq 1 ] ; then
         FILE_SEQUENCE=l # last
      else
         FILE_SEQUENCE=s
      fi

      if [ ${#p_nF[*]} -eq 1 ] ; then
        POST_PROC=t
      else
        POST_PROC=
      fi

      if [ ${SHOW_NEXT:-0} -gt 0 ] ; then
        if [ ${SHOW_NEXT} -gt $(( ++fileCount - 1 )) ] ;  then
          # update the container with arrays of filenames
          unset p_nF[0]  # pop from the front

          # store the residual array
          eval ${metaW}=\( \${p_nF[*]} \)
          std_out flush "Path: ${PROJECT_DATA}/${subPath}"
          std_out flush "  File: ${nextFile}"
          continue
        else
          finally
        fi
      fi

      # select a free host and store the name  in variable 'nextHost'
      # returns 0 for success and 1 for no free host found
      host_nap=1  # increment for a sleeping period

      test ! ${DEBUG_MANAGER} && voidX
      while \
#trace \
       ! getHost
      do

#      while ! getHost ; do
#trace \
        sleep $host_nap
        test $host_nap -lt $maxSleep && host_nap=$(( host_nap +1 ))
      done
      test ! ${DEBUG_MANAGER} && voidX

      # check disk space
      if [ ${ENABLE_DISK_SPACE_INQ:-f} = t ] ; then
#trace \
        inqDiskSpace
      fi

      if [ ${SHOW_NEXT:-f} = t ] ; then
        std_out flush "Next: ${subPath} ${nextFile}"
        finally
      fi

#trace \
      callQaExecutor ${nextFile}

      # store the corresponding pid
      nF_PID[${nFcurr}]=${currPID}

#      if [ ${PROGRESS_BAR} ] ; then
        # get number of data files for progress estimation
#      fi

      displayStatusLine ${#nextFile} "\rNEXT File: ${nextFile}"

      # limit the number of executions
      if [ ${NEXT:-0} -gt 0 -a ${NEXT:-0} -eq $(( ++fileCount )) ] ;  then
#trace \
        wait_fnct

        if [ ${FLOW_TRACE:-f} = t ] ; then
          FLOW_TRACE_EXIT=t
          return $retVal
        fi

        return 0  # unconditional
      fi

      # update the container with arrays of filenames
      unset p_nF[0]  # pop from the front

      # store the residual array
      eval ${metaW}=\( \${p_nF[*]} \)

#      if [ ${NO_STATUS} = f  ] ; then
#        if [ ${SIMPLE_STATUS_LINE:-f} = t ] ; then
#          # get number of data files for progress estimation

#          displayStatusLine ${#nextFile[nF_IX]} "\rNEXT File: ${nextFile[nF_IX]}"
#        fi
#      fi

      if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
        wcRes=($( wc -l ${DEBUG_MANAGER}.${dbgCycle}))
        # cycle after every block of 1000000 lines
        if [ ${wcRes[0]} -gt 1000000 ] ; then
          set +x
          exec 2<&7 7<&-
          exec 7<&2
          exec 2>${DEBUG_MANAGER}.$((++dbgCycle))
          set -x
        fi
      fi
    done

    # pipes have never been filled
    test ${nFmax} -eq 0 && break

    # all pipes are busy
    if [ ${END_OF_PATHS} ] ; then
      local k
      for(( k=0 ; k < nFmax ; ++k )) ; do
        if [ ! ${isDrainedPipe[k]} ] ; then
          sleep $op_nap
          test $op_nap -lt $maxSleep && op_nap=$(( op_nap +1 ))
          continue 2
        fi
      done
      break
    else
      # container still not initially filled
      if [ $nFmax -lt ${maxNumExecThreads} ] ; then
        break
      fi
    fi

  done

  return $retVal
}

rmBlock()
{
  test $# -lt 2 && return

  test ! -f $1 && return  # no log-file at all, yet

  local file=$1
  local pattern=$2

  # get all lines with line numbers having ' file: pattern'
  local nums num sz i
  declare -a nums

  nums=($(grep -n "[[:space:]]*file:[[:space:]]*${pattern}" $1 ))

  # extract the numbers
  nums=(${nums[*]#file:})
  nums=(${nums[*]%${pattern}*})
  nums=(${nums[*]%:})

  # remove all blocks by default. $2==num keeps the num last occurrences
  sz=$(( ${#nums[*]} -1))
  test $3 && sz=$((sz-$3))
  test ${sz} -lt 0 && return

  for(( i=sz ; i > -1  ; --i )) ; do
    num=$(( ${nums[i]} -1 ))

    sed  -i "$num,/status:/ d" $file
  done

  return
}

rmConsistTableEntry()
{
  test $# -lt 2 && return

  local file=$1
  local pattern=$2

  # get all lines with line numbers having ' file: pattern'
  local nums num sz i
  declare -a nums

  nums=($(grep -n "[[:space:]]*file:[[:space:]]*${pattern}" $1 ))

  # extract the numbers
  nums=(${nums[*]#file:})
  nums=(${nums[*]%${pattern}*})
  nums=(${nums[*]%:})

  # remove all blocks by default. $2==num keeps the num last occurrences
  sz=$(( ${#nums[*]} -1))
  test $3 && sz=$((sz-$3))
  test ${sz} -lt 0 && return

  for(( i=sz ; i > -1  ; --i )) ; do
    num=$(( ${nums[i]} -1 ))

    sed  -i "$num,/status:/ d" $file
  done

  return
}

initExample()
{
  # an example for CORDEX
    #if [ "${QA_TABLES}" ] ; then
    #  setKWL EXAMPLE_PATH=${QA_TABLES}/example
    #  example_args[${#example_args[*]}]="--up=no"
    #else
    #  setKWL EXAMPLE_PATH=$PWD/example
    #  setKWL QA_TABLES=${EXAMPLE_PATH}
    #fi

    if [ "${QA_RESULTS}" ] ; then
      setKWL EXAMPLE_PATH=${QA_RESULTS}
      example_args[${#example_args[*]}]="-E_QA_RESULTS=${QA_RESULTS}"
    else
      setKWL EXAMPLE_PATH=$PWD
      example_args[${#example_args[*]}]="-E_QA_RESULTS=${EXAMPLE_PATH}"
    fi

    . $QA_SRC/scripts/parseConfigFile QA_TABLES

    example_args[${#example_args[*]}]='-m -f qa-test.task'

    test ${EXAMPLE_PATH:0:1} != '/' && EXAMPLE_PATH=$PWD/$EXAMPLE_PATH

    if ! mkdir -p ${EXAMPLE_PATH} &> /dev/null ; then
      echo "could not mkdir ${EXAMPLE_PATH}, please use option --work=path"
      exit
    fi

    cd ${EXAMPLE_PATH}

    \rm -rf results config.txt data tables qa-test.task .qa-dkrz

    echo "make examples in $EXAMPLE_PATH " > $TTY
    echo "make qa_test.task " > $TTY

    # prepare the example, if not done, yet
    cp $QA_SRC/example/templates/qa-test.task .
    sed -i "s%PROJECT_DATA=data%PROJECT_DATA=${EXAMPLE_PATH}/data%" \
           qa-test.task
    sed -i "s%QA_RESULTS=results%QA_RESULTS=${QA_RESULTS}%" \
           qa-test.task

    # data
    echo "make data " > $TTY
    tar --bzip2 -xf ${QA_SRC}/example/templates/data.tbz
    fs=( $( find data -name "*.txt" ) )

    if which ncgen &> /dev/null ; then
      for f in ${fs[*]} ; do
        ncgen -x -k 3 -o ${f%txt}nc $f
        \rm -f $f
      done
    else
      echo "building data in example requires the ncgen utility"
      exit
    fi

    export CONFIG_FILE=${EXAMPLE_PATH}/config.txt
    touch $CONFIG_FILE

    $QA_SRC/install --config-file=${CONFIG_FILE} \
                    ${QA_TABLES:+--qa_tables=${QA_TABLES}} \
                    up CORDEX

  return
}

##//! Send annotations to the list of email recipients.

sendEMail()
{
  if [ ! ${EMAIL_TO[0]} ] ; then
     return
  fi

  local sendSub
  sendSub="QA ${PROJECT} ${CURR_LOG_FNAME}: ${sendSubject}"

  # activate backslash escaped chars
  local sendT
  sendT="$( echo -e $sendText )"

  eval ${MAIL} -s \"\$sendSub\"  ${EMAIL_TO[*]} <<!
$sendT
!

  return
}

rmEmptyPaths()
{
  local subPath
  while read -a subPath ; do
    rmdir -p ${QA_RESULTS}/data/${subPath[1]} &> /dev/null
  done < ${pathListFile}

  return
}


setKWL()
{
  # store keywords for empty values
  local key=${1%%=*}
  local value
  test "${1}" != "${1/=/}" && value=${1#*=}

  # was key already defined?
  local i
  for(( i=0 ; i < ${#keyWordList[*]} ; ++i )) ; do
     if [ "${keyWordList[i]}" = "$key" ] ; then
      if [ ${value} ] ; then
        # key available, but value has changed
        local asdf
        eval asdf=\$${key}
        if [ "$asdf" != "$value" ] ; then
          eval $key="$value"
        fi
      fi

      return
    fi
  done

  # add key to the list
  keyWordList[${#keyWordList[*]}]=$key

  # only if set in this script
  test "${value}" && eval $key="$value"

  return
}

splitAtRegExp()
{
  # $1 : a path

  set -f

  # split selected path into components
  local items=( ${1//\// } )

  splitRE_0=

  # look for an alpha-numeric sub-path leading a selected path
  local i
  for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
    if expr match "${items[i]}" "[[:alnum:]_-]\{${#items[i]}\}" &> /dev/null ; then
      # only accept valid paths
      splitRE_0=${splitRE_0}/"${items[i]}"
    else
      break
    fi
  done

  local slash=
  for(( ; i < ${#items[*]} ; ++i )) ; do
    splitRE_1=${splitRE_1}${slash}${items[i]}
    local slash=/
  done

  set +f

  return 0
}

##//! Launcher of annotations

##/*!
## Determination where annotations go to: experiment _logfile,
## session-logfile, email, and/or terminal.
##*/

std_out()
{
  # if a tty device is connected, then output immediately,
  # else collect contents and print to a default file and/or
  # send by email.
  test $# -eq 0 && return

  if [ "$1" = ttyOnly ] ; then
    if is_TTY ; then
       shift
       echo -e -n "$*" > $TTY
    fi
    return
  fi

  if [ "$1" = add  ] ; then
    # only collect items
    shift
    outputText[${#outputText[*]}]="$*"

    return
  fi

  if [ "$1" = flush ] ; then
    shift
    test $# -gt 0 && outputText[${#outputText[*]}]="$*"

    # nothing to flush
    test ${#outputText[*]} -eq 0 && return
  fi

  local j str0

  # flush
  if [ ${#outputText[*]} -eq 0 -a $# -eq 0 ] ; then
    return
  fi

  # email
  # print to session logfile
  sendText=
  for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
    sendText="${sendText}${outputText[j]}"
  done

  if [ ${SESSION_LOGDIR} ] ; then
    log_sessMessage "${outputText[*]}"
  fi

  if is_TTY ; then
     shift
     echo -e -n "${sendText}\n" > $TTY
  else
    if [ ${EMAIL_TO[0]} ] ; then
     sendEMail
    fi
  fi

  # neither email nor session logfile. Store in dir NoDevice
#  if [ ${isSent} = f ] ; then
#    # str0 gets the filename for undeliverables
#    if mkdir -p $QA_SRC/NoDevice &> /dev/null ; then
#      str0="undeliv_$( date +'%FT%T' )_${HOSTNAME%%.*}".txt
#      echo "$str0" >> $QA_SRC/NoDevice/$str0

#      for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
#        echo -e -n "${outputText[j]}" >> $QA_SRC/NoDevice/$str0

#      for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
#        echo -e -n "${outputText[j]}" >> $QA_SRC/NoDevice/$str0
#      done
#    fi
#  fi

  unset outputText

  return
}

terminate()
{
  isTERM=t

  finally
  exit
}

testFileLink()
{
  # Purpose: when the file of the current path is
  # a symbolic link, then make links to corresponding QA results.
  # If corresponding QA results don't exist, the append the subpath
  # to the genuine data (Note: D A T A ).
  # If the path to the genuine data is LOCKed, then remove the lock.

  # Note: only links of files within ${subPath}
  # are taken into account. A symbolic link of the prefixed
  # ${PROJECT_DATA} path is always dereferenced.

  local src_filename link_target_path

  # Note: multiple filenames are allowed, but all
  # would be ascociated with the same QA result file.
  # Thus,considering the first one is sufficient

  # Take into account not only a qa-result file but, also new
  # associated files, e.g. freqDist. These could be added
  # after having established the link to the qa result file.

  # dereferenced link
  deref_link link_target_path ${PROJECT_DATA}/${subPath}/$nextFile

  src_filename=${link_target_path##*/}
  link_target_path=${link_target_path%/*.nc}

  if [ ! ${link_target_path} ] ; then
    # this should not happen
    sendSubject="No valid link detected from source"

    sTxt[0]="3info: 1"
    sTxt[1]="3 - link detection failed for: ls -l ${PROJECT_DATA}/${subPath}/$nextFile"

    std_out flush "${sTxt[1]:4}"

    sendEMail
    return 0
  fi

  local saveSubPath=${subPath}
  local dest_path=${QA_RESULTS}/data

  if [ "${link_target_path:0:1}" = '/' ] ; then
    # a link to the outside of PROJECT_DATA will always be dereferenced
    test "${link_target_path:0:${#PROJECT_DATA}}" != ${PROJECT_DATA} && return 1

    # adjust for a link with an absolute path
    link_target_path=$QA_RESULTS/data${link_target_path#${PROJECT_DATA}}

    subPath=${link_target_path#${QA_RESULTS}/data/}
  else
    # Any relative path?
    subPath=${link_target_path}

    local tmp_subPath
    if [ ${saveSubPath:0:1} = '/' ] ; then
      tmp_subPath=${saveSubPath:1}
    else
      tmp_subPath=${saveSubPath}
    fi

    while [ ${subPath:0:1} = '.' ] ; do
      subPath=${subPath#*/}
      tmp_subPath=${tmp_subPath%/*}
    done

    subPath=/${tmp_subPath}/${subPath}
  fi

  # qa the genuine data
  if [ ${subPath:0:1} = '/' ] ; then
     tryCom \
        mkdir -p ${QA_RESULTS}/data/${subPath:1}
  else
     tryCom \
        mkdir -p ${QA_RESULTS}/data/${subPath}
  fi

# point to the genuine filename from here
  local ix=0
  local f fBase tmp

  tmp=$( getDateRange ${src_filename} )
  f=${src_filename%.nc}
  f=${f%_${tmp}}
  fBase[ix]=$f

#  getFilenameBase
  operatePipes ${subPath}

#trace \
  checkClosedMessages

  # link to genuine qa results
  mkLinks ${dest_path} ${subPath} ${src_filename} ${fBase[ix]} &

  return
}

testLocks()
{
  # $1: fBase[ix]
  # $2: qa_*.nc if any

  # apply rules, clearings, and test for qa_note files
  if \
#trace \
  applyRules $1 ; then
    return 0  # not selected
  fi

  # conditions for clearing are described in the configuration file
  if [ ${CLEAR} ] ; then
#trace \
    if [ ${LOG_PATH_INDEX[0]} ] ; then
      if ! getExperimentName P ${subPath} ; then
        getExperimentName F $1
      fi
    else
      getExperimentName F $1
    fi

    # if CLEAR=only or SHOW_CLEAR was set, then try another variable
    if clear ; then
      eval $2=
      return 1
    fi
  fi

  if \
#trace \
  checkLockFile $1 ; then
#    if [ ${PROGRESS_BAR} ] ; then
#      local num=$( ls -d ${PROJECT_DATA}/${subPath}/${1}*.nc \
#                    | grep -c . )
#    fi

    return 0  # is blocked
  fi

  return 1
}

testPathLink()
{
  # Purpose: when the current path is
  # a symbolic link, then make links for the QA results, too.
  # Input parameter: subPath
  # Return 0 for a link

  # Note: only a link of a directory within ${subPath}
  # is taken into account. A symbolic link to the outside
  # is
  # A symbolic link of the prefixed
  # ${PROJECT_DATA} path is always dereferenced.

  if [ $# -eq 0 ] ; then
     return 1
  fi

  local dest_path

  dest_path=$QA_RESULTS/data${1}

  local link_target_path

  # test path components. Note: pc starts with a '/'
  local pc
  pc=${1%/}

  while [ "${pc}" != "${pc%/*}" ] ; do

    if [ ! -h ${PROJECT_DATA}$pc ] ; then
       pc=${pc%/*}  # try the preceding component
       continue  # not a symbolic link
    fi

    # dereferenced link
    deref_link link_target_path ${PROJECT_DATA}$pc

    if [ ! ${link_target_path} ] ; then
       # this should not happen
       sendSubject="No valid link detected from source"

       sTxt[0]="3info: 1"
       sTxt[1]="3 - Link detection failed for: ls -l ${PROJECT_DATA}$pc"

       std_out flush "${sTxt[1]:4}"

       sendEMail
       continue
    fi

    # a link to the outside of PROJECT_DATA will be dereferenced
    if [ "${link_target_path:0:1}" = '/' -a \
         "${link_target_path:0:${#PROJECT_DATA}}" != ${PROJECT_DATA} ] ; then
       return 1
    fi

    # the dir where to place the link must exist.
    test ! -e $QA_RESULTS/data${pc%/*} && return 0  # try again later

    # is there already a link in the qa dir tree?
    if [ -e "$QA_RESULTS/data${pc}" ] ; then
       # is the link still the one it should be?
       local dest_lnk

       # dereferenced link
       deref_link dest_lnk  ${QA_RESULTS}/data$pc

       # link exists; nothing has changed
       if [ "$link_target_path" = "$dest_lnk" ] ; then
         return 0
       fi
    fi

    # we don't care if a broken link is produced; this may get
    # valid in a later iteration.
    ln -sf ${link_target_path} $QA_RESULTS/data${pc}

    local text
    text="Symbolic link for a sub-tree"

    if [ ${link_target_path:0:1} = / ] ; then
      sTxt[0]="3info: 1"
      sTxt[1]="3 - $QA_RESULTS/data${pc} --> ${link_target_path}"
    else
      sTxt[0]="info: 2"
      sTxt[1]="3 - common_path: $QA_RESULTS/data${pc%/*}"
      sTxt[2]="3 - link: ${pc##*/} --> ${link_target_path}"
    fi

    test ${#text} -gt 28 && log_sessMessage "$text"

    return 0
  done

  return 1
}

timer()
{
  # on normal execution, this function is closed externally in time
  limit=10
  for(( i=0 ; i < limit ; ++i )) ; do
    if ! ps -p $1 -o pid= &> /dev/null  ; then
      # there is no more active job
      return 0
    fi

    sleep 1
  done

  kill -TERM $1
  return 1
}

##//! Flow tracing of the session

##/*!
## Just for debugging or efficiency considerations.
##*/

trace()
{
  local ret

  if [ ${FLOW_TRACE:-f} = f ] ; then
    eval $*
    return $?
  fi

  trc_curr_depth=$(( trc_curr_depth + 1 ))

  local i j index str t0 t1 token count

  # estimating trace itself
  t0=$(unixTime.x dec)

  count=0
  while [ $count -lt 5 ] ;  do  # a workaround for erroneous expr exit value
  # find the function name, perhaps embedded
  if expr match "$*" '[[:alpha:]]*=' &> /dev/null ; then
    # variabel=( $(fnctName ... )
    token=$( expr match "$1" '[[:alpha:]]*=*[^[:alpha:]]*\([[:alpha:]]\+\)' )
  elif expr match "$*" '[^[:alpha:]]' &> /dev/null ; then
    # $(fnctName ... )
    token=$( expr match "$*" '[^[:alpha:]]*\([[:alpha:]]\+\)' )
    test ! ${token} && token="$1"
  else
    token="$1"  # a plain function was called
  fi

    count=$(( count + 1 ))
    test ${#token} -gt 1 && break
  done;

  for(( index=0 ; index < ${#trc_name[*]} ; ++index )) ; do
    test ${trc_name[index]} = trc_${token} && break
  done

  if [ ${index} = ${#trc_name[*]} ] ; then
    trc_name[$index]=trc_${token}
    trc_time[$index]=0.
    trc_count[$index]=0
    trc_depth[$index]=$trc_curr_depth
  fi

  t1=$(unixTime.x dec 2> /dev/null)
  trc_time[0]=\
$(echo "${trc_time[0]} + $t1 - $t0 - $traceCalibTime" \
   | bc -l 2> /dev/null)
  trc_count[0]=$(( trc_count[0] + 1 ))

  # time measurement of called function
  t0=$(unixTime.x dec)
  eval $*
  ret=$?
  t1=$(unixTime.x dec)

  trc_time[$index]=\
$(echo "${trc_time[$index]} + $t1 - $t0 - $traceCalibTime" | bc -l 2> /dev/null)
  trc_count[$index]=$(( trc_count[$index] + 1 ))
  trc_depth[$index]=$trc_curr_depth

  trc_curr_depth=$(( trc_curr_depth - 1 ))

  test ${FLOW_TRACE_EXIT:-f} = t && exit

  return $ret
}

traceCalibration()
{
  local prg

  if [ ${HOSTNAME} = surge ] ; then
    prg="${QA_SRC}/bin/unixTime.x dec"
  elif [ ${HOSTNAME:0:3} = liz ] ; then
    prg="${QA_SRC}/bin_l/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = pass ] ; then
    prg="${QA_SRC}/bin_p/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = bliz ] ; then
    prg="${QA_SRC}/bin_b/unixTime.x dec"
  else
    echo "traceCalibration: executable unixTime.x not found"
    exit
  fi

  local t0 t1

  traceCalibTime=0
  trc_curr_depth=0

  t0=$( $prg )
  trace :
  t1=$( $prg )

  traceCalibTime=$(echo "${t1} -${t0}" | bc -l 2> /dev/null)
  traceStartTime=$( $prg )

  return
}

tracePrint()
{
  # part of the elapsed time used in trace itself will be removed

  local i j tab resid sum out total sz
  sum=0.
  out=qa_flowtrace.lst

  total=$(unixTime.x dec)
  total=$(echo "$total - ${traceStartTime}" | bc -l 2> /dev/null )

  echo -e "Function\t\tdepth\tcount\ttime [s]" > $out
  echo -e "--------\t\t-----\t---------------" >> $out

  sz=${#trc_name[*]}

  # accumulated time [%]
  for(( i=1 ; i < sz ; ++i )) ; do
    # skip secondary processes
    test ${trc_depth[i]} -gt 1 && continue

    sum=$(echo "$sum + ${trc_time[i]}" | bc -l 2> /dev/null )
  done

  # residual time
  local tmp
  tmp=$(echo "$total - ${sum}" | bc -l )
  trc_time[${#trc_time[*]}]=$tmp

  # elapsed time
  trc_time[${#trc_time[*]}]=${total}

  # position of the decimal point of the accumulated times
  local pre
  pre=0
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         test $j -gt $pre && pre=$j
         break
       fi
     done
  done

  # formatting of the acc. times
  local trm
  trm=6
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         # trim decimal digits
         trc_time[$i]=${trc_time[i]:0:$(( j + trm))}
         local k
         for(( k=0 ; k < pre - j ; ++k )) ; do
           trc_time[$i]=" ${trc_time[i]}"
         done
         break
       fi
     done
  done

  for(( i=1 ; i < sz ; ++i )) ; do
    if [ ${#trc_name[i]} -lt 12 ] ; then
      tab='\t\t\t'
    elif [ ${#trc_name[i]} -lt 20 ] ; then
      tab='\t\t'
    else # [ ${#trc_name[i]} -lt 28 ] ; then
      tab='\t'
    fi

    echo -e -n "${trc_name[i]:4}"       >> $out
    echo -e -n "${tab}${trc_depth[i]}"  >> $out
    echo -e -n "\t${trc_count[i]}"      >> $out
    echo -e   "\t${trc_time[i]}"        >> $out

  done

  echo -e "--------\t\t \t----------------" >> $out
  tab='\t\t'

  echo -e "residual time${tab}\t\t${trc_time[sz]}" >> $out

  echo -e "elapsed time${tab}\t\t${trc_time[$((sz+1))]}" >> $out
}

##//! Command launcher

##/*!
## Several commands are passed to this launcher making processing
## more robust against interruptions of the file system.
##*/

tryCom()
{
  test ! ${DEBUG_MANAGER} && voidX

  # leading options:
  # a) return the status after trying:   get_status
  # b) set temporary sleep period:       set_sleep
  # c) set temporary REATTEMPT_LIMIT:    set_limit

  # $*:   command [with args]

  # Examples:
  # 1) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # 2) for f in $(tryCom ls -d *) ; do ... ; done
  # 3) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # There is a dependency on bash's "noglob" setting

  local i arg tCStatus
  local countAttempts=0
  local n_shift=0

  local limits=$REATTEMPT_LIMIT
  local t_slice=$SLEEP_TIME
  local getStatus=f

  for(( i=1 ; i <= $# ; ++i )) ; do
    arg=${!i}
    if [ "${arg}" = 'get_status' ] ; then
       getStatus=t
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_limit=' ] ; then
       limits=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_sleep=' ] ; then
       t_slice=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    else
      break
    fi
  done

  test ${n_shift} -gt 0 && shift ${n_shift}

  local retVal

  while : ; do
    $* 2> /dev/null # execute the command

    tCStatus=$?
    if [ $tCStatus -eq 0 ] ; then
      retVal=0
      break
    fi

    # for a configuration defined period
    if [ $((countAttempts++)) -lt $limits ] ; then
       sleep $t_slice
       continue
    fi

    # number of allowed attempts exceeded.

    # it is ok to have failed, so just return
    if [ ${getStatus} = t ] ; then
      retval=$tCStatus
      break
    fi

    # Try a last time to get the error message.
    local failed
    failed="$( $* 2>&1 )"

    # for instance rm returns an error text with embedded ` and '
    failed=$( echo "$failed" | sed 's%`%%g' |sed "s%'%%g")

    std_out add "Failed command in qa-DKRZ: $*"
    std_out add "\n${failed}"

    sendSubject="command failed after ${limits} reattempts"
    std_out flush

    finally

    retVal=1
    break
  done

  test ! ${DEBUG_MANAGER} && voidX
  return $retVal
}

tr_option()
{
  local line="$1"
  local i pref value

  # only parameter of -e, -E is processed
  if [ "${2}" = '-e' ] ; then
    for(( i=0 ; i < ${#line} ; ++i )) ; do
      if [ ${line:i:1} != - ] ; then
        line=${line:i}
        break
      else
        pref="${pref}-"
      fi
    done

    local value x_line
    declare -a x_line
    x_line=( ${line/=/ } )

    line="${x_line[0]/% /}"
    line=$( echo "${line/% /}" | tr "[:lower:]" "[:upper:]" )
    line=$( echo "${line}" | tr "-" "_" )
    line=${line//QC/QA}

    value=
    if [ ${#x_line[*]} -gt 1 ] ; then
      value="=${x_line[1]/% /}"
    fi

    arg=${pref}${line}${value}
  fi

  return
}

voidX()
{
  # toggle between set -x and set +x in a way that
  # restores the original setting after calling twice

  if [ ${isSetX:-t} = t ] ; then
    test "$(set -o |grep xtrace | awk '{print $2}')" = off && return

    # first call
    isSetX=on
  fi

  # restore previous setting
  if [ ${isSetX} = off ] ; then
    set -x
    isSetX=on
  else
    set +x
    isSetX=off
  fi

  return
}

wait_fnct()
{
  test ${SHOW_CALL:-f} = t && return

  # a getSelectedPath process is still running; kill it
  if ps -p ${getPathPID:-0} -o pid= &> /dev/null  ; then
     kill -9 $getPathPID &> /dev/null
     wait $getPathPID &> /dev/null
  fi

  local count=0
  local i isAnyAlive

  while : ; do

    isAnyAlive=f

    for(( i=0 ; i < nFmax ; ++i )) ; do
       # skip pipe with a running job
       if [ ${nF_PID[i]} -gt 0 ]  ; then
         if ps -p ${nF_PID[i]} -o pid= &> /dev/null  ; then
           # there is still an active job for this fBase
           isAnyAlive=t
           sleep 1

           if [ ${isTERM:-f} = t -o $((count++)) -gt ${ZOMBIE_LIMIT} ] ; then
             # kill immediately of after a while
             kill -TERM ${nF_PID[i]} &> /dev/null
             wait ${nF_PID[i]} &> /dev/null
           fi
         fi
       fi
    done

    test $isAnyAlive = f && break
  done

  return
}

##//! Determine the path to QA-0.4/scripts from $0


##//! Entry to this script

##/*!
## Definition of traps, init() and check().
##*/

##main()
##{
######## main ############
setKWL CURR_DIR=$PWD

comLineArgs=( $* )

test $# -eq 1 -a "${1:0:9}" = '--install' && STOP_AFTER_INSTALL=t
umask 002

# resolve symbolic links and relative paths
getSrcPath
test ${QA_SRC##*/} = scripts && QA_SRC=${QA_SRC%/scripts}

initial_params=( $* )

# store the tty, if any
if tty -s ; then TTY=$(tty) ; fi

QA_CONFIG=qa-config
QA_FILE_EXECUTER=qa-exec-check

rootPID=$$

args=()
for OPTARG in $* ; do
  if [ ${OPTARG:0:2} = '-E' -o ${OPTARG:0:2} = '-e' ] ; then
     if [ ${#OPTARG} -gt 2 ] ; then
       if [ ${OPTARG:2:1} = '_' -o ${OPTARG:2:1} = '-' ] ; then
         optargs=( -e ${OPTARG:3} )
       else
         optargs=( -e ${OPTARG:2} )
       fi
     else
       optargs=( -e )
       continue
     fi
  else
     optargs=( ${optargs[*]} ${OPTARG} )
  fi

  for arg in ${optargs[*]} ; do
    test ${arg} = '-h' -o ${arg} = '--help' \
        && . $QA_SRC/scripts/qa-help
    test ${arg} = '--debug' && set -x

    tr_option $arg $prev_opt
    OPTNAME=${arg%%=*}

    if [ ${OPTNAME} = DEBUG -o ${OPTNAME} = DEBUG_M ] ; then
       set -x
    elif [ "${OPTNAME}" = EXAMPLE ] ; then
      QA_EXAMPLE=t

    elif [ ${OPTNAME} = CONFIG_FILE ] ; then
      export CONFIG_FILE=${OPTARG#*=}
    elif [ ${OPTNAME} = QA_CONFIG ] ; then
      QA_CONFIG=${OPTARG#*=}
    elif [ ${OPTNAME} = QA_TABLES ] ; then
      QA_TABLES=${OPTARG#*=}
    elif [ ${OPTNAME} = QA_SRC ] ; then
      QA_SRC=${OPTARG#*=}
    elif [ ${OPTNAME} = WORK ] ; then
      QA_RESULTS=${OPTARG#*=}
      arg="QA_RESULTS=${OPTARG#*=}"
    fi

    args[${#args[*]}]=${arg}
    prev_opt=${arg}
  done
  optargs=()
done

# HOME/.qa-dkrz/config.txt by default
. ${QA_SRC}/scripts/getConfigFile

# is it in a conda built?
. ${QA_SRC}/scripts/getCondaPath

init ${args[*]}

test ${FLOW_TRACE:-f} = t && traceCalibration

trap terminate TERM
trap finally EXIT

test ${SHOW_EXP:-f} = t -o ${SHOW_LOG_FNAME:-f} = t && getAllExps && exit

### the inifinit loop: over all experiments again and again ####
check

##}
